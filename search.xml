<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[容器]]></title>
    <url>%2F2019%2F10%2F19%2F%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[容器主要包括 Collection 和 Map 两种，Collection 存储着对象的集合，而 Map 存储着键值对（两个对象）的映射表。 Collection Collection主要分为三类：Set，List，Queue。 Set是无序存储，而且不会存储重复的元素。 Queue是一个队列，只能从一端插入元素，从另一端取出元素。 Map Map存储的是键值对。 ListArrayListArrayList的底层实现是一个数组，其访问速度比较快，但是插入删除速度比较慢。 12//transient表示这个成员不可以被序列化transient Object[] elementData; 扩容添加元素时使用 ensureCapacityInternal() 方法来保证容量足够，如果不够时，需要使用 grow() 方法进行扩容，新容量的大小为 oldCapacity + (oldCapacity &gt;&gt; 1)，也就是旧容量的 1.5 倍。 扩容操作需要调用 Arrays.copyOf() 把原数组整个复制到新数组中，这个操作代价很高，因此最好在创建 ArrayList 对象时就指定大概的容量大小，减少扩容操作的次数。 1234567891011private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125; 删除123456789101112public E remove(int index) &#123; //检查index是否合法 rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) //需要将index+1后面的位置都往前移动 System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue;&#125; Vector它的实现与 ArrayList 类似，但是使用了 synchronized 进行同步,是线程安全的。 12345678910111213public synchronized boolean add(E e) &#123; modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true;&#125;public synchronized E get(int index) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); return elementData(index);&#125; 扩容Vector 的构造函数可以传入 capacityIncrement 参数，它的作用是在扩容时使容量 capacity 增长 capacityIncrement。如果这个参数的值小于等于 0，扩容时每次都令 capacity 为原来的两倍。 1234567891011private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ? capacityIncrement : oldCapacity); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity);&#125; 与ArrayList不同 加了synchronized关键字，是线程安全的。 Vector 每次扩容请求其大小的 2 倍（也可以通过构造函数设置增长的容量），而 ArrayList 是 1.5 倍。 但是，一般来说，在面对多线程的情况，我们也很少使用Vector，因为效率比较低。 CopyOnWriteArrayListCopyOnWriteArrayList也是基于写时复制以及读写分离的思想。 当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。对CopyOnWrite容器进行并发的读的时候，不需要加锁，因为当前容器不会添加任何元素。 CopyOnWriteArrayList内部维护了一个数组，而且是volatile的。 12/** The array, accessed only via getArray/setArray. */private transient volatile Object[] array; get12345678910111213public E get(int index) &#123; return get(getArray(), index);&#125;/** * Gets the array. Non-private so as to also be accessible * from CopyOnWriteArraySet class. */final Object[] getArray() &#123; return array;&#125;private E get(Object[] a, int index) &#123; return (E) a[index];&#125; 实现非常简单，因为根据写时复制，读取数据的时候数据不会修改，所以肯定是线程安全的。 add12345678910111213141516171819public boolean add(E e) &#123; final ReentrantLock lock = this.lock; //1. 使用Lock,保证写线程在同一时刻只有一个 lock.lock(); try &#123; //2. 获取旧数组引用 Object[] elements = getArray(); int len = elements.length; //3. 创建新的数组，并将旧数组的数据复制到新数组中 Object[] newElements = Arrays.copyOf(elements, len + 1); //4. 往新数组中添加新的数据 newElements[len] = e; //5. 将旧数组引用指向新的数组 setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125;&#125; 需要添加lock，避免出现多个线程写数据。 将旧数组拷贝，对新数组进行写操作，操作完成将数组引用指向新数据。 实际上核心就是读写其实是在两个不同的容器中，所以就可以进行同时读写。 与读写锁区别COW与读写锁都使用了读写分离的思想，都可以同时多个线程读。 但是COW读写线程是可以同时的。 缺点 数据一致性问题。COW实际上会有读延迟情况的发生。所以，假如对数据实时一致性很高，最好不使用COW。 内存问题。COW每次写数据都需要重新拷贝一个数组，假如高并发写或者对象比较大，会造成频繁GC。COW其实是不适用于高并发频繁写的场景。 LinkedList基于双向链表实现。 SetSet的核心概念就是集合内所有元素不重复。 HashSet基于HashTable实现。 12private transient HashMap&lt;E,Object&gt; map;private static final Object PRESENT = new Object(); 意思就是HashSet的集合其实就是HashMap的key的集合，然后HashMap的val默认都是PRESENT。HashMap的定义即是key不重复的集合。使用HashMap实现，这样HashSet就不需要再实现一遍。 12345678910111213141516//遍历的是HashMap的keypublic Iterator&lt;E&gt; iterator() &#123; return map.keySet().iterator();&#125;public boolean contains(Object o) &#123; return map.containsKey(o);&#125;public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125;public void clear() &#123; map.clear();&#125; LinkedHashSetLinkedHashSet会根据add，remove这些操作的顺序在遍历时返回固定的集合顺序。 TreeSet基于TreeMap实现。 TreeSet即是一组有次序的集合，如果没有指定排序规则Comparator，则会按照自然排序。 MapHashMapJava容器 CopyOnWriteArrayList]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发容器]]></title>
    <url>%2F2019%2F10%2F19%2F%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池]]></title>
    <url>%2F2019%2F10%2F19%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[创建线程池123456//五个参数的构造函数public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) corePoolSize,核心线程数。 线程池新建线程的时候，如果当前线程总数小于corePoolSize，则新建的是核心线程，如果超过corePoolSize，则新建的是非核心线程。 即使核心线程处于闲置状态，核心线程也不会被销毁。 maximumPoolSize,最大线程数。线程池中能创建的最大的线程数。 keepAliveTime.当非核心线程数闲置时长超过keepAliveTime,就会将其销毁。 workQueue。 该线程池中的任务队列：维护着等待执行的Runnable对象。 当所有的核心线程都在干活时，新添加的任务会被添加到这个队列中等待处理，如果队列满了，则新建非核心线程执行任务。 ThreadPoolExecutor的策略当一个任务被添加进线程池时： 线程数量未达到corePoolSize，则新建一个线程(核心线程)执行任务 线程数量达到了corePoolSize，则将任务移入队列等待 队列已满，新建线程(非核心线程)执行任务 队列已满，总线程数又达到了maximumPoolSize，抛出异常 饱和策略 (RejectedExecutionHandler)：当等待队列已满，线程数也达到最大线程数时，线程池会根据饱和策略来执行后续操作，默认的策略是抛弃要加入的任务。 线程池种类 newFixedThreadPool，固定线程数的线程池。 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; newCachedThreadPool。 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; newScheduledThreadPool(). 1234567public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS, new DelayedWorkQueue());&#125;//DelayedWorkQueue 这个队列接收到任务时，首先先入队，只有达到了指定的延时时间，才会执行任务 newSingleThreadPool(). 123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125;]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Semaphore and CountDownLatch]]></title>
    <url>%2F2019%2F10%2F16%2F%C2%96Semaphore-and-CountDownLatch%2F</url>
    <content type="text"><![CDATA[SemaphoreSemaphore叫做信号量，是一种共享锁，当其permit大于0时，线程可以获取锁，当permits小于0时，线程只能等待获取锁，等其他线程释放。 Semophore也有公平锁和非公平锁两种状态。 12345678910111213141516171819202122//公平共享锁尝试获取acquires个信号量protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; if (hasQueuedPredecessors()) //前面是否有排队，有则返回获取失败 return -1; int available = getState(); //剩余的信号量（旋转寿司店剩余的座位） int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) // 剩余信号量不够，够的情况下尝试获取（旋转寿司店座位不够，或者同时来两对情况抢座位） return remaining; &#125;&#125;//非公平共享锁尝试获取acquires个信号量final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; int available = getState(); //剩余的信号量（旋转寿司店剩余的座位） int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) // 剩余信号量不够，够的情况下尝试获取（旋转寿司店座位不够，或者同时来两对情侣抢座位） return remaining; &#125;&#125; CountDownLatchCountDownLatch用于协调多个线程的同步，能让一个线程在等待其他线程执行完任务后，再继续执行。内部是通过一个计数器去完成实现。 CountDownLatch是通过一个计数器来实现的，计数器的初始值为线程的数量。每当一个线程完成了自己的任务后，可以调用countDown()，计数器的值就会减1。当计数器值到达0时，它表示所有的线程已经完成了任务，然后在闭锁上等待的线程(使用await()阻塞)就可以恢复执行任务。 使用场景 一个线程执行需要等待其他线程执行完毕，才能继续执行 1234567891011121314151617181920212223public static void main(String[] args) &#123; CountDownLatch latch = new CountDownLatch(10); for (int i = 0; i &lt; 10; i++) &#123; new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + "---start"); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + "---finish"); //计数器减一 latch.countDown(); &#125;).start(); &#125; try &#123; //将主线程阻塞在latch，直到latch的计数器等于0 latch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("执行完毕-----"); &#125; 常用方法CountDownLatch通过state来表示计数器。 await() 将当前线程阻塞在CountDownLatch上，直到计数器的数量减少至0. await(long timeout, TimeUnit unit)，与await()不同的是，设置了超时等待，等到了时间，不管计数器是不是0，都会继续执行。 countDown()，计数器数量减一。当计数器数量减为0时，将await()的线程唤醒。 CyclicBarrier用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行。 和 CountdownLatch 相似，都是通过维护计数器来实现的。线程执行 await() 方法之后计数器会减 1，并进行等待，直到计数器为 0，所有调用 await() 方法而在等待的线程才能继续执行。 CyclicBarrier 和 CountdownLatch 的一个区别是，CyclicBarrier 的计数器通过调用 reset() 方法可以循环使用，所以它才叫做循环屏障。 CyclicBarrier 有两个构造函数，其中 parties 指示计数器的初始值，barrierAction 在所有线程都到达屏障的时候会执行一次。]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读写锁]]></title>
    <url>%2F2019%2F10%2F14%2F%E8%AF%BB%E5%86%99%E9%94%81%2F</url>
    <content type="text"><![CDATA[ReentrantReadWriteLock：一个资源能够被多个读线程访问，或者被一个写线程访问，但是不能同时存在读写线程。 读锁是共享锁，可以有多个线程读；而写锁是独占锁，同时只可能有一个线程写。 共享变量读锁可以多线程访问，写锁只可以有一个线程访问，我们很容易想到可以使用两个变量来表示读写状态。但是，AQS却只是使用一个state来实现。 123456789static final int SHARED_SHIFT = 16;static final int SHARED_UNIT = (1 &lt;&lt; SHARED_SHIFT);static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1;static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1;/** Returns the number of shared holds represented in count */static int sharedCount(int c) &#123; return c &gt;&gt;&gt; SHARED_SHIFT; &#125;/** Returns the number of exclusive holds represented in count */static int exclusiveCount(int c) &#123; return c &amp; EXCLUSIVE_MASK; &#125; 举个例子来看： 这里有两个关键方法sharedCount和exclusiveCount，通过名字可以看出sharedCount是共享锁的数量，exclusiveCount是独占锁的数量。 共享锁通过对c像右位移16位获得，独占锁通过和16位的1与运算获得。 state前十六位代表读锁，后十六位代表写锁。 举个例子，当获取读锁的线程有3个，写锁的线程有1个（当然这是不可能同时有的），state就表示为0000 0000 0000 0011 0000 0000 0000 0001，高16位代表读锁，通过向右位移16位（c &gt;&gt;&gt; SHARED_SHIFT）得倒10进制的3，通过和0000 0000 0000 0000 1111 1111 1111 1111与运算（c &amp; EXCLUSIVE_MASK），获得10进制的1。 由于16位最大全1表示为65535，所以读锁和写锁最多可以获取65535个。 WriteLock写锁是一把独占锁，同时只可能有一个线程访问，而且不可能与读锁同时存在，所以与ReentrantLock不同的是，WriteLock不仅要判断是否还有其它写线程占用，还要考虑是否还有读线程占用。 读锁是否存在。因为要确保写锁的操作对读锁是可见的。如果在存在读锁的情况下允许获取写锁，那么那些已经获取读锁的其他线程可能就无法感知当前写线程的操作。因此只有等读锁完全释放后，写锁才能够被当前线程所获取，一旦写锁获取了，所有其他读、写线程均会被阻塞。 123456789101112131415161718192021protected final boolean tryAcquire(int acquires) &#123; Thread current = Thread.currentThread(); int c = getState(); //获取共享变量state int w = exclusiveCount(c); //获取写锁数量 if (c != 0) &#123; //有读锁或者写锁 // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) //写锁为0（证明有读锁），或者持有写锁的线程不为当前线程 return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error("Maximum lock count exceeded"); // Reentrant acquire setState(c + acquires); //当前线程持有写锁，为重入锁，+acquires即可 return true; &#125; if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) //CAS操作失败，多线程情况下被抢占，获取锁失败。CAS成功则获取锁成功 return false; setExclusiveOwnerThread(current); return true;&#125; 锁降级在获取写锁的时候，如果资源存在读锁，那么肯定是无法获取写锁的。 但是，在获取读锁的时候， 如果对资源加了写锁，其他线程无法再获得写锁与读锁，但是持有写锁的线程，可以对资源加读锁（锁降级），主要原因是因为在同一个线程内，写锁所做的修改读锁时立即可见的，但是在别的线程内就没有可见性了。 12345678910111213141516171819202122232425262728class CachedData &#123; Object data; //保证状态可见性 volatile boolean cacheValid; ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); void processCachedData() &#123; rwl.readLock().lock(); if (!cacheValid) &#123; // 在获取写锁前必须释放读锁 rwl.readLock().unlock(); rwl.writeLock().lock(); //再次检查其他线程是否已经抢到 if (!cacheValid) &#123; //获取数据 data = ... cacheValid = true; &#125; // 在释放写锁之前通过获取读锁来降级 rwl.readLock().lock(); //释放写锁，保持读锁 rwl.writeLock().unlock(); &#125; use(data); rwl.readLock().unlock(); &#125; &#125; ReadLock 申请读锁，资源上没有写锁，且读锁数量小于最大值，申请读锁成功。 申请读锁，资源上有写锁，且写锁就在本线程上，那么申请成功。 读写锁 锁降级 读写锁]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发，java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReentranrLock]]></title>
    <url>%2F2019%2F10%2F13%2FReentranrLock%2F</url>
    <content type="text"><![CDATA[ReentrantLock是可重入锁，它实现了Lock接口。 可重入锁就是说同一个线程可以多次申请到该锁。 ReentrantLock有公平锁和非公平锁两种方式。 12345678public void m() &#123; * lock.lock(); // block until condition holds * try &#123; * // ... method body * &#125; finally &#123; * lock.unlock() * &#125; * &#125; 使用lock和unlock进行加锁和解锁。 而lock和unlock都是调用sync的。 123456789//加锁public void lock() &#123; sync.lock();&#125;//释放锁public void unlock() &#123; sync.release(1);&#125; sync是ReentranrtLock的成员变量，他继承了AQS,所以，核心是AQS的实现，而且有两个内部类，一个可以实现公平锁，一个实现非公平锁。 1234private final Sync sync;abstract static class Sync extends AbstractQueuedSynchronizer &#123;&#125;static final class NonfairSync extends Sync&#123;&#125;static final class FairSync extends Sync&#123;&#125; 在构造函数中可以定义是公平锁还是非公平锁。 123public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); &#125; ReentrantLock主要还是基于AQS实现的，我们主要关注他重写的一些方法，包括tryAcquire()和release(). tryAcquire()1234567891011121314151617181920212223242526272829303132333435363738394041//非公平锁 final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; //重入锁的实现 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125;//公平锁protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125; 公平锁和非公平锁最大的区别就是!hasQueuedPredecessors()，公平锁需要先判断等待队列中是否有前驱节点在等待。如果有，则说明有线程比当前线程更早的请求资源，根据公平性，当前线程请求资源失败；如果当前节点没有前驱节点，才有做后面的逻辑判断的必要性。 公平锁非公平锁的吞吐量较高例如默认状态的ReentrantLock 有新线程来了先争夺一下锁，没成功再去排队。公平锁是java关键字synchronized的重锁模式，谁来了都乖乖排队，后来的线程不能争夺锁，一定要入队列等待前一个线程来unpark自己，除非队列里没有其他线程。 可以在构造函数中设置公平锁还是非公平锁。 尝试锁定可以使用tryLock()来尝试上锁，假如在一定的时间内获取锁失败，那么就会放弃等待。 可中断锁lock.lockInterruptibly() 对线程中断 interrupt() 做出响应。 使用 lockInterruptibly() 则该线程在等待锁的过程中，如果被中断interrupt()，则直接抛出中断异常来立即响应中断。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package JUC;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;public class ReentrantLock3 &#123; Lock lock=new ReentrantLock(); void m1() &#123; lock.lock(); System.out.println("t1 start"); try &#123; TimeUnit.SECONDS.sleep(10000000); System.out.println("t1 end"); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; void m2() &#123; try &#123; lock.lockInterruptibly(); System.out.println("t2 start"); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block System.out.println("t2 interrupted!"); &#125; &#125; public static void main(String[] args) &#123; ReentrantLock3 test=new ReentrantLock3(); Thread t2=new Thread(test::m2); new Thread(test::m1).start(); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; t2.start(); t2.interrupt(); &#125;&#125;//t1 start//t2 interrupted! 与synchronized区别 ReentrantLock是JDK实现的，synchronized是JVM实现的。 ReentrantLock需要手动释放，而且最好在finally中释放。 ReentrantLock支持公平锁。 ReentrantLock支持中断锁。 ReentrantLock支持条件队列。 现在来说，经过JVM的优化，synchronized的效率已经很高了，一般来说，如果没有必须要使用ReentrantLock的功能。最好使用synchronized。因为JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM优化]]></title>
    <url>%2F2019%2F10%2F12%2FJVM%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Java有三种编译器i，一种是前端编译器，就是将java文件转变为class文件，这是在编译阶段。一种运行期编译器(JIT编译器)，将字节码文件转变为机器码，这是在运行阶段。 编译期优化编译过程主要分为： 词法语法分析。 填充符号表。 注解处理器。 语义分析。 生成字节码。 泛型泛型是java语法糖的一种，他的本质是参数化类型。 泛型主要有泛型类，泛型接口，泛型方法。 Java中的泛型只存在于编译阶段，只是用来在编译阶段进行数据校验的作用，在运行时期，泛型就被擦除了，替换为他的原生类型。 1234567891011List&lt;String&gt; stringArrayList = new ArrayList&lt;String&gt;();List&lt;Integer&gt; integerArrayList = new ArrayList&lt;Integer&gt;();Class classStringArrayList = stringArrayList.getClass();Class classIntegerArrayList = integerArrayList.getClass();if(classStringArrayList.equals(classIntegerArrayList))&#123; System.out.println("----equals----");&#125;//输出：----equals---- 在运行阶段，泛型已被擦除，所以，都被替换为ArrayList，是相同的。 个人觉得泛型的作用就是在编译阶段进行语义的审查的作用。 泛型擦除只是从字节码中擦除了，但是元数据中还是保留了泛型信息，所以，我们还是可以通过反射手段取得参数化类型。 获取方法返回泛型 12Method method = MyClass.class.getMethod("getStringList", null);Type returnType = method.getGenericReturnType(); 获取成员变量泛型参数 12Field field = MyClass.class.getField("stringList");Type genericFieldType = field.getGenericType(); 运行期优化 javac 将程序源代码编译，转换成 java 字节码，JVM 通过解释字节码将其翻译成对应的机器指令，逐条读入，逐条解释翻译。很显然，经过解释执行，其执行速度必然会比可执行的二进制字节码程序慢很多。为了提高执行速度，引入了 JIT 技术。 当JVM发现某一段代码执行特别频繁的时候，就会认为他是热点代码，为了提高执行效率，虚拟机就会用过JIT编译器将这些代码编译成机器码，缓存下来。 那么，为什么不直接编译呢？ 首先，如果这段代码本身在将来只会被执行一次，那么从本质上看，编译就是在浪费精力。因为将代码翻译成 java 字节码相对于编译这段代码并执行代码来说，要快很多。当然，如果一段代码频繁的调用方法，或是一个循环，也就是这段代码被多次执行，那么编译就非常值得了。因此，编译器具有的这种权衡能力会首先执行解释后的代码，然后再去分辨哪些方法会被频繁调用来保证其本身的编译。 JVM是采用解释器与编译器并行的架构。 程序启动时，解释器首先发挥作用，省掉编译的时间，迅速执行。 程序运行后，随着时间的推移，编译器发挥作用，将代码编译成机器码，获取更高执行效率。 HotSpot有两个即时编译器，Client Compiler和Server Compiler，一个注重优化速度，一个注重优化质量。 Client Compiler：编译速度快，优化简单可靠。 Server Compiler：会有一些编译时间比较长的优化。 热点代码热点代码有两类。 被多次调用的方法。 被多次执行的循环体。 那么，怎么计数呢？ 基于采样的热点探测。虚拟机周期性的检查各个线程栈顶，如果某个方法频繁出现，那么这就是一个热点方法。 基于计数器的热点探测。为每个方法(代码块)建立计数器，统计执行次数。 在HotSpot采用的是第二种，有方法计数器来统计方法调用次数，回边计数器来统计循环代码调用次数。当计数器超过阈值的时候，就会对其进行编译。 优化技术公共子表达式消除如果一个表达式E计算过了，且他的值没有任何变化，那么E再次出现就没必要再次计算，直接用结果。 方法内联内联举例： 1234567public int add(int a, int b , int c, int d)&#123; return add(a, b) + add(c, d); &#125; public int add(int a, int b)&#123; return a + b; &#125; 内联之后： 123public int add(int a, int b , int c, int d)&#123; return a + b + c + d;&#125; 调用一个方法需要建立栈帧等，成本比较大，方法内联可以很好的消除方法调用的成本。 内联条件： 热点代码。 方法体不是太大。 如果希望方法被内联，尽量用private、static、final修饰，这样jvm可以直接内联。如果是public、protected修饰方法jvm则需要进行类型判断，因为这些方法可以被子类继承和覆盖，jvm需要判断内联究竟内联是父类还是其中某个子类的方法。 但是，内联并不是这么简单的，我们的程序中大多都是虚方法(不用private，final，static修饰的)，那么就会有多态的可能，不知道会不会有子类重写了方法。 JVM团队采用CHA来解决这个问题。 方法是非虚方法，直接内联即可。 是虚方法，看程序内该方法是否有多个实现，若只有一个，直接内联。 若有多个，采取内联缓存。内联缓存中保存的是第一次调用使用的版本，并且以后每次调用都会比较版本信息，一致，继续使用。 不一致，取消内联。 逃逸分析 方法逃逸：一个对象在方法中被定义后，可能被其他方法使用。 线程逃逸：一个对象在方法中定义后，可以被别的线程访问到。 如果一个对象没有逃逸，可以对其做以下优化。 栈上分配。如果一个对象没有逃逸出方法之外，那么只会在一个方法内部访问，这样的话，将其分配在栈上，方法结束，对象自动被销毁，GC压力会小很多。 同步消除。因为一个对象没有逃逸，所以不会被外部线程访问到，所以同步措施也可以消除。 标量替换。标量是指一个数据无法再分解成更小的数据，例如基本数据类型，引用类型等。如果一个对象不会被外部访问，可以选择不创建这个对象，转而直接创建这个对象会被方法调用的成员变量。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lock and AQS]]></title>
    <url>%2F2019%2F10%2F10%2FLock-and-AQS%2F</url>
    <content type="text"><![CDATA[JUC包JUC包目录。 其中包含了两个子包：atomic以及lock，另外在concurrent下的阻塞队列以及executors，这些类主要是依靠volatile以及CAS实现的。 整体结构如图： Lock简介Lock是一个接口。 与synchronized相比，Lock拥有了锁获取和释放的可操作性，可中断的获取锁以及超时获取锁等多种synchronized关键字所不具备的同步特性。 Lock是一个接口，有许多实现他的类，比如ReentranrLock，但是查看他的源码会发现大部分方法都是在调用他的内部类Sync的方法，而Sync继承了AQS，因此，Lock实现的核心还是AQS。 AQSAQS的设计是使用模板方法设计模式，他将一些相同部分的代码实现，将不同的代码放到不同的子类中去；而且，在AQS的方法中，也会调用子类的代码。模板设计模式 例如： 1234567891011//子类需要重写tryAcquire()protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125;//但是在AQS的模板方法中又调用了tryAcquire()public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; 因此，AQS只需要实现各自不同的tryAquire()就行了,比如是公平锁还是非公平锁，是独占锁还是共享锁。 AQS提供的模板方法可以分为3类： 独占式获取与释放同步状态； 共享式获取与释放同步状态； 查询同步队列中等待线程情况； AQS的功能分为两种：独占和共享 独占锁，每次只能有一个线程持有锁，比如ReentrantLock就是以独占方式实现的互斥锁. 共享锁，允许多个线程同时获取锁，并发访问共享资源，比如ReentrantReadWriteLock. AQS实现AQS中有两个重要的成员，一个是CLH队列，一个是state。 stateAQS使用一个int类型的成员变量state来表示同步状态，当state&gt;0时表示已经获取了锁，当state = 0时表示释放了锁。 CLHCLH是一个先进先出的队列。如果当前线程竞争锁失败，那么AQS会把当前线程以及等待状态信息构造成一个Node加入到同步队列中，同时再阻塞该线程。当获取锁的线程释放锁以后，会从队列中唤醒一个阻塞的节点(线程)。 CLH的头节点是空的，啥也不存的。 12345678910if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; NodeNode代表的是一个正在阻塞等待的线程。 123456789101112131415161718192021222324252627282930//当前节点处于共享模式的标记 static final Node SHARED = new Node(); //当前节点处于独占模式的标记 static final Node EXCLUSIVE = null; //线程被取消了 static final int CANCELLED = 1; //释放资源后需唤醒后继节点 static final int SIGNAL = -1; //等待condition唤醒 static final int CONDITION = -2; //工作于共享锁状态，需要向后传播， //比如根据资源是否剩余，唤醒后继节点 static final int PROPAGATE = -3; //等待状态，有1,0,-1,-2,-3五个值。分别对应上面的值 volatile int waitStatus; //前驱节点 volatile Node prev; //后继节点 volatile Node next; //等待锁的线程 volatile Thread thread; //等待条件的下一个节点，ConditonObject中用到 Node nextWaiter; 独占锁的获取123456//通过子类的tryAcquire()获取锁，不同的子类有不同的实现，要是获取失败，则执行acquireQueued(addWaiter(Node.EXCLUSIVE), arg)，将该线程放入CLH public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; 入队操作：主要采取CAS+自旋的方式，一开始采用CAS快速入队，失败了之后再采用自旋操作。 1234567891011121314151617181920212223242526272829303132333435//入队操作，mode = Node.EXCLUSIVE，独占锁private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); /* 这段代码进行快速入队，实际上与enq中差不多。这样做的原因是： 把最有可能成功执行的代码直接写在最常用的调用处，因为在线程数不多的情况下，CAS还是很难失败的。因此 这种写法可以节省多条指令。因为调用enq需要一次方法调用，进入循环，比较null，然后才到了红框中一样 的代码。大概类似于内联函数的优化 总而言之，节省指令，提高效率。 */ Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node; &#125;private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail;//记录尾节点 if (t == null) &#123; //由于采用lazy initialize,当队列为空时，需要进行初始化 //通过CAS设置head和tail节点 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t;//将node的前节点设置为原tail节点 if (compareAndSetTail(t, node)) &#123;//CAS更新tail节点，更新成功则将原tail节点的后节点设置为node，返回原tail节点，入列成功； t.next = node; return t; &#125; &#125; &#125; 在把node插入队列末尾后,它并不立即挂起该节点中线程,因为在插入它的过程中,前面的线程可能已经执行完成,所以它会先进行自旋操作acquireQueued(node, arg),尝试让该线程重新获取锁!当条件满足获取到了锁则可以从自旋过程中退出，否则继续。 1234567891011121314151617181920212223final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; //如果节点的前驱是队列的头节点并且能拿到资源，获取锁成功，结束 final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; //判断当前节点是否应该被挂起。 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 判断节点是否应该被挂起，当前驱节点是SIGNAL的时候，直接挂起线程。 1234567891011121314151617181920212223242526272829private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) //前驱节点的状态是SIGNAL，说明前驱节点释放资源后会通知自己 //此时当前节点可以安全的park()，因此返回true return true; if (ws &gt; 0) &#123; //前驱节点的状态是CANCLLED，说明前置节点已经放弃获取资源了 //此时一直往前找，直到找到最近的一个处于正常等待状态的节点 //并排在它后面，返回false do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; //前驱节点的状态是0或PROPGATE，则利用CAS将前置节点的状态置 //为SIGNAL，让它释放资源后通知自己 //如果前置节点刚释放资源，状态就不是SIGNAL了，这时就会失败 // 返回false compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; &#125; private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted(); &#125; acquire()整个流程： 调用子类的tryAquire()尝试获取资源，成功，直接返回。失败，继续。 获取失败，将该线程生成一个Node节点通过addWaiter(Node.EXCLUSIVE), arg)添加到等待队列。 插入等待队列后，防止在这个阶段资源又有了。根据前置节点状态状态判断是否应该继续获取资源。如果前驱是头结点，继续尝试获取资源；获取成功，返回；否则，继续。 在每一次自旋获取资源过程中，失败后调用shouldParkAfterFailedAcquire(Node, Node)检测当前节点是否应该park()。 如果前置节点是SIGNAL状态，就挂起，返回true。 如果前置节点状态为CANCELLED，就一直往前找，直到找到最近的一个处于正常等待状态的节点，并排在它后面，返回false，acquireQueed()接着自旋尝试。 前置节点处于其他状态，利用CAS将前置节点状态置为SIGNAL。当前置节点刚释放资源，状态就不是SIGNAL了，导致失败，返回false。但凡返回false，就导致acquireQueed()接着自旋尝试。 若返回true，则调用parkAndCheckInterrupt()中断当前节点中的线程。若返回false，则接着自旋获取资源。 parkAndCheckInterrupt()挂起线程。 共享锁的获取共享锁就是同时可以有多个线程访问。实现与独占锁差不多，唯一的不同就是需要判断是否还有剩余资源。 公平锁非公平锁的吞吐量较高例如默认状态的ReentrantLock 有新线程来了先争夺一下锁，没成功再去排队。公平锁是java关键字synchronized的重锁模式，谁来了都乖乖排队，后来的线程不能争夺锁，一定要入队列等待前一个线程来unpark自己，除非队列里没有其他线程。 中断锁当线程等待的时候，如果被interrupt()，那么直接抛出中断异常。 1234567public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg); &#125; 超时锁在获取锁的过程中，超过某一个时长，自动放弃获取。 释放锁首先调用子类的tryRelease()方法释放锁,然后唤醒后继节点,在唤醒的过程中,需要判断后继节点是否满足情况,如果后继节点不为空且不是作废状态,则唤醒这个后继节点,否则从tail节点向前寻找合适的节点,如果找到,则唤醒。 ConditionObject这是AQS的一个内部类，其维护了一个condition队列。主要有await()和signal()等方法。 await()await()：当前线程处于阻塞状态，直到调用signal()或中断才能被唤醒。 将当前线程封装成node且等待状态为CONDITION。 释放当前线程持有的所有资源，让下一个线程能获取资源。 加入到条件队列后，则阻塞当前线程，等待被唤醒。 如果是因signal被唤醒，则节点会从条件队列转移到等待队列；如果是因中断被唤醒，则记录中断状态。两种情况都会跳出循环。 若是因signal被唤醒，就自旋获取资源；否则处理中断异常。 condition队列与CLH最大的不同就是CLH是双向列表，condition队列是单向列表。 CLH是单向列表的原因是可能需要获取前置节点的一些属性，比如说查看前置节点是不是头节点之类的。 ConditionObject详解ConditionObject用来实现锁的等待通知机制。ConditionObject内部维护了一个等待队列，与CLH不同的是这个队列是单向链表。 与Object wait/notify区别Object的wait和notify/notify是与对象监视器配合完成线程间的等待/通知机制，而Condition与Lock配合完成等待通知机制，前者是java底层级别的，后者是语言级别的，具有更高的可控制性和扩展性。 Condition能够支持多个等待队列（new 多个Condition对象），而Object方式只能支持一个。 Condition能够支持超时时间的设置，而Object不支持。 await方法 void await() throws InterruptedException:当前线程进入等待状态，如果其他线程调用condition的signal或者signalAll方法并且当前线程获取Lock从await方法返回，如果在等待状态中被中断会抛出被中断异常； long awaitNanos(long nanosTimeout)：当前线程进入等待状态直到被通知，中断或者超时。 boolean awaitUntil(Date deadline) throws InterruptedException：当前线程进入等待状态直到被通知，中断或者到了某个时间。 signal方法 void signal()：唤醒一个等待在condition上的线程(第一个线程，条件队列是一个FIFO的队列)，将该线程从等待队列中转移到同步队列中，如果在同步队列中能够竞争到Lock则可以从等待方法中返回。 void signalAll()：与1的区别在于能够唤醒所有等待在condition上的线程。 await实现原理await主要做了三件事： 将线程包装成Node，插入到条件队列。 释放线程拥有的锁。 阻塞当前线程。 1234567891011121314151617181920212223public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 1. 将当前线程包装成Node，尾插入到等待队列中 Node node = addConditionWaiter(); // 2. 释放当前线程所占用的lock，在释放的过程中会唤醒同步队列中的下一个节点 int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; // 3. 当前线程进入到等待状态 LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; // 4. 自旋等待获取到同步状态（即获取到lock） if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); // 5. 处理被中断的情况 if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125; 插入到条件队列： 123456789101112131415161718private Node addConditionWaiter() &#123; Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; //将当前线程包装成Node Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else //尾插入 t.nextWaiter = node; //更新lastWaiter lastWaiter = node; return node;&#125; 与等待队列不同的是，条件队列没有头节点。 释放锁： 1234567891011121314151617final int fullyRelease(Node node) &#123; boolean failed = true; try &#123; int savedState = getState(); if (release(savedState)) &#123; //成功释放同步状态 failed = false; return savedState; &#125; else &#123; //不成功释放同步状态抛出异常 throw new IllegalMonitorStateException(); &#125; &#125; finally &#123; if (failed) node.waitStatus = Node.CANCELLED; &#125;&#125; 结束await()状态： 12345678//当前节点被移动到了同步队列中（即另外线程调用的condition的signal或者signalAll方法），while中逻辑判断为false后结束while循环while (!isOnSyncQueue(node)) &#123; // 3. 当前线程进入到等待状态 LockSupport.park(this); //当线程被中断，会退出循环 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break;&#125; AQS详解]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
        <tag>源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例模式]]></title>
    <url>%2F2019%2F10%2F10%2F%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[一开始，我们写的单例模式是这样的。 123456789public class Singleton &#123; private Singleton instance = null; public Singleton getInstance()&#123; if(instance==null)&#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 但是，这种方式有一个问题，就是无法解决多线程问题。 于是，对方法加锁： 123456789public class Singleton &#123; private Singleton instance = null; public synchronized Singleton getInstance()&#123; if(instance==null)&#123; //lineA instance = new Singleton(); &#125; return instance; &#125;&#125; 这样，就解决了并发的问题。 但是，在每次调用方法我们都需要加锁，加锁实际上性能会变低，实际上调用方法只会出现一次instance==null，以后的每一次调用都是直接返回instance对象。 因此，可以将if判断语句提取出来。 1234567891011public class Singleton &#123; private Singleton instance = null; public Singleton getInstance()&#123; if(instance==null) &#123; //lineA synchronized (this) &#123; instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 但是，这样还是有问题，假设线程A执行完了lineA进入同步语句，但还并没有创建实例，此时线程B也执行到了lineA，但是instance==null，还是会重复创建实例。 于是，采用DCL解决，在同步语句块内部再进行一次if判断。 12345678910111213public class Singleton &#123; private Singleton instance = null; public Singleton getInstance()&#123; if(instance==null) &#123; synchronized (this) &#123; if(instance==null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 那么，这样就没有问题了吗？ 并不是，因为new Singleton()这个语句实际上它并不是一个原子操作。 它有三条指令构成： 1.在堆中开辟一块内存（new） 2.调用对象的构造函数对内存进行初始化（invokespecial） 3.最后将引用赋值给变量（astore），这一句instance就赋值了。 所以，因为重排序的存在，CPU有可能产生指令重排序，比如1-3-2，这样的话，另一个线程可能在对象还没有初始化的时候就拿走了instance，造成问题。 于是，我们可以加上volatile，禁止指令重排序。 12345678910111213public class Singleton &#123; private volatile Singleton instance = null; public Singleton getInstance()&#123; if(instance==null) &#123; synchronized (this) &#123; if(instance==null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 单例模式]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[volatile关键字]]></title>
    <url>%2F2019%2F10%2F09%2Fvolatile%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[Java 内存模型JMM定义了内存中各个共享变量访问的规则。 共享变量包括包括实例字段 静态字段和构成数组的元素，即所有线程都可以访问到的，不包括局部变量和方法参数，这是线程私有的。 JMM规定了所有共享变量都存储在主内存，每条线程还有自己的工作内存，工作内存除了存储线程私有的局部变量以及方法参数等，还有该线程中需要用到的主内存中的共享变量的拷贝。 线程对变量的操作(读取赋值等)必须在工作内存中进行，首先要将变量从主内存拷贝的自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量。 工作内存是每个线程的私有数据区域，因此不同的线程间无法访问对方的工作内存，线程间的通信(传值)必须通过主内存来完成。 设置工作内存的目的主要是为了解决内存与处理器速度不一致的问题，一般来说，主内存存放在内存中，工作内存存放在高速缓存中，因此，工作内存数据操作速度很快。 但是，JMM有一个问题，就是主内存与工作内存不一致的问题，可能工作内存修改了某个工作变量，但是没有同步到主内存中。 重排序问题计算机在执行程序时，为了提高性能，编译器和处理器的常常会对指令做重排。 如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。 当两条指令没有数据依赖性的时候，就又可能对他进行指令重排序。 JMM 三个特性JMM规定了三个特性，原子性，有序性，可见性。 其中，重排序破坏了有序性，JMM内存结构破坏了可见性。 原子性原子性是指一个操作是不可中断的，要么全部执行成功要么全部执行失败，有着“同生共死”的感觉。 JMM中read，load，use，store，write都是原子操作，所以，基本数据类型的操作都是具备原子性的(long和double例外，因为long和double占64位，可能存在读取半个变量)。 如果应用场景需要一个更大的原子范围，可以使用sychronized等来解决。 可见性可见性是指当一个线程修改了共享变量后，其他线程能够立即得知这个修改。变量更新后，主内存中立即更新，并且根据缓存一致性协议，其他线程中的变量也会更新。 除了sychronized和volatile，final也具有可见性，因为final是不可以被修改的。但是，也有一个前提，被final修饰的字段在构造器中一旦初始化完成，并且没有this引用逃逸，那么其他线程就能看到final字段的值。 12345678910111213141516public class ThisEscape &#123; public final int id; public final String name; public ThisEscape(EventSource&lt;EventListener&gt; source) &#123; id = 1; source.registerListener(new EventListener() &#123; public void onEvent(Object obj) &#123; System.out.println("id: "+ThisEscape.this.id); System.out.println("name: "+ThisEscape.this.name); &#125; &#125;); name = "flysqrlboy"; &#125; &#125; ThisEscape在构造函数中引入了一个内部类EventListener，而内部类会自动的持有其外部类（这里是ThisEscape）的this引用。source.registerListener会将内部类发布出去，从而ThisEscape.this引用也随着内部类被发布了出去。但此时ThisEscape对象还没有构造完成 —— id已被赋值为1，但name还没被赋值，仍然为null。 有序性volatilevolatile保证可见性与有序性，但是不保证原子性。 保证可见性在生成汇编代码时会在volatile修饰的共享变量进行写操作的时候会多出Lock前缀的指令。 如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。 所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。 这样针对volatile变量通过这样的机制就使得每个线程都能获得该变量的最新值。 保证顺序性volatile会在内存中和插入一个内存屏障指令(lock指令)，来禁止指令重排序。 因此，volatile读操作跟普通变量相比，没有什么差别，但是写操作因为要插入许多内存屏障，因此，效率会低一些。 happens-before在发生操作B之前，操作A产生的影响都能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等，它与时间上的先后发生基本没有太大关系。 程序次序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作 管程锁定规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。同步快中线程安全。 volatile变量规则：对一个volatile变量的写操作happens-before对这个变量的读操作。 线程启动规则：Thread.start() happens before 所有操作。 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C 线程终止规则：线程中所有操作都happens-before对此线程的终止检测。 对象finalize规则：一个对象的初始化完成（构造函数执行结束）先行于发生它的finalize()方法的开始 程序中断规则：对线程interrupted()方法的调用先行于被中断线程的代码检测到中断时间的发生。 满足任意一个原则，对于读写共享变量来说，就是线程安全。 关于可见性的一些问题123456789101112131415161718192021public class T &#123; /*volatile*/ boolean running=true; void m() &#123; System.out.println("m start"); while(running) &#123; &#125; System.out.println("m end"); &#125; public static void main(String args[]) &#123; T t =new T(); new Thread(()-&gt;t.m(),"t1").start(); try &#123; //睡眠1s，保证t1先执行 TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; t.running=false; &#125;&#125; 这段代码肯定是无法停止t1线程的，加上volatile就可以了。 那么，对m加上sychronized呢？ 1234567891011121314151617181920public class T &#123; boolean running=true; synchronized void m() &#123; System.out.println("m start"); while(running) &#123; &#125; System.out.println("m end"); &#125; public static void main(String args[]) &#123; T t =new T(); new Thread(()-&gt;t.m(),"t1").start(); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; t.running=false; &#125;&#125; 这样还是不可以的，因为sychronied修饰的代码块中并没有改写running变量,synchronized会把同步块内更新的值再给同步到内存中。 但是，当我在循环里里面加了一个打印输出的语句，就可以终止线程了，为什么呢？ 123456789101112131415161718192021222324package Thread;import java.util.concurrent.TimeUnit;public class T &#123; boolean running=true; void m() &#123; System.out.println("m start"); while(running) &#123; System.out.println("2"); &#125; System.out.println("m end"); &#125; public static void main(String args[]) &#123; T t =new T(); new Thread(()-&gt;t.m(),"t1").start(); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; t.running=false; &#125;&#125; 实际上，JVM对于现代的机器做了最大程度的优化，也就是说，最大程度的保障了线程和主存之间的及时的同步，也就是相当于虚拟机尽可能的帮我们加了个volatile，但是，当CPU被一直占用的时候，同步就会出现不及时，也就出现了后台线程一直不结束的情况。 也就是说，在cpu空闲的时候，可能会更新一下主内存的内容。 比如，我们在循环中sleep一下，亦可以结束线程。 volatile使用场景状态标志用volatile来修饰一个Boolean状态标志，用于指示发生了某一次的重要事件，例如完成初始化或者请求停机。 1234567891011volatile boolean shutdownRequested; ... public void shutdown() &#123; shutdownRequested = true; &#125; public void doWork() &#123; while (!shutdownRequested) &#123; // do stuff &#125;&#125; DCL通过volatile禁止指令重排序。 12345678910111213//使用 volatile 修饰。 private volatile static Singleton sInstance; public static Singleton getInstance() &#123; if (sInstance == null) &#123; //(0) synchronized (Singleton.class) &#123; //(1) if (sInstance == null) &#123; //(2) sInstance = new Singleton(); //(3) &#125; &#125; &#125; return sInstance; &#125; 读操作远远大于写操作如果读操作远远超过写操作，您可以结合使用内部锁和volatile变量来减少公共代码路径的开销。下面的代码中使用synchronized确保增量操作是原子的，并使用volatile保证当前结果的可见性。如果更新不频繁的话，该方法可实现更好的性能，因为读路径的开销仅仅涉及volatile读操作，这通常要优于一个无竞争的锁获取的开销。 1234567public class CheesyCounter &#123; private volatile int value; public int getValue() &#123; return value; &#125; public synchronized int increment() &#123; return value++; &#125;&#125;]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[synchronized关键字]]></title>
    <url>%2F2019%2F10%2F09%2Fsynchronized%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[使用锁定的是对象1234567891011public class T &#123; private Object o=new Object(); private int count=10; public void m() &#123; synchronized(o) &#123; count--; System.out.println(Thread.currentThread().getName()+&quot;count=&quot;+count); &#125; &#125; &#125; 1.当一个线程想要去执行这段代码，必须要获得o的锁，当o被其他线程占用时，该线程必须要等其他线程释放o的锁，再去获得o的锁，才能执行。 2.synchronized关键字锁定的是对象不是代码块,demo中锁的是object对象的实例 3.可能锁对象包括： this， 临界资源对象，Class 类对象。 4.关于线程安全：加synchronized关键字之后不一定能实现线程安全，具体还要看锁定的对象是否唯一。 5.synchronized关键字修饰普通方法等同于synchronized(this) 静态方法上锁12345678910/* * 静态方法加锁相当于给T.class文件枷锁 * */public class T &#123; private static int count=10; public synchronized static void m() &#123; count--; System.out.println(Thread.currentThread().getName()+"count="+count); &#125;&#125;复制代码 给静态方法上锁，锁定的是类对象，类的.class文件是唯一的，所以说synchronize修饰静态方法或者锁定的对象是类的.class文件的时候在多线程中是可以实现线程安全的.。 需要注意的是如果一个线程A调用一个实例对象的非static synchronized方法，而线程B需要调用这个实例对象所属类的静态 synchronized方法，是允许的，不会发生互斥现象，因为访问静态 synchronized 方法占用的锁是当前类的class对象，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。 同步和非同步方法同时调用12345678910111213141516171819202122232425262728293031323334353637public class T &#123; public synchronized void m1()&#123; System.out.println("m1 start------"); try &#123; Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println("m1 end--------"); &#125; public void m2() &#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println("m2-----"); &#125; public static void main(String args[]) &#123; T t=new T(); //相当于new 一个线程，在run方法里执行m1 lamda表达式 /*new Thread(new Runnable() &#123; @Override public void run() &#123; // TODO Auto-generated method stub &#125; &#125;); */ new Thread(()-&gt;t.m1(),"t1").start(); new Thread(()-&gt;t.m2(),"t1").start(); &#125;&#125; 线程t1首先获得了当前对象t的锁，并执行m1。因为m2非同步的，不需要获得锁就可以执行，所以t2不需要获得锁就可以直接执行m2.只有执行synchronized方法才需要申请那把锁。 可重入锁1234567891011121314151617181920212223242526272829303132333435public class Test1 &#123; synchronized void m1() &#123; System.out.println(Thread.currentThread().getName()+" m1"); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; m2(); &#125; synchronized void m2() &#123; System.out.println(Thread.currentThread().getName()+" m2"); &#125; public static void main(String[] args) &#123; Test1 t=new Test1(); // TODO Auto-generated method stub new Thread(()-&gt;&#123; t.m1(); &#125;,"t1").start(); new Thread(()-&gt;&#123; t.m1(); &#125;,"t2").start();; &#125;&#125;输出：t1 m1t1 m2t2 m1t2 m2 所谓重入锁，指的是以线程为单位，当一个线程获取对象锁之后，这个线程可以再次获取本对象上的锁，而其他的线程是不可以的，synchronized和ReentrantLock都是可重入锁。可重入锁的意义在于防止死锁。实现原理实现是通过为每个锁关联一个请求计数和一个占有它的线程。当计数为0时，认为锁是未被占有的。线程请求一个未被占有的锁时，jvm讲记录锁的占有者，并且讲请求计数器置为1 。如果同一个线程再次请求这个锁，计数将递增；每次占用线程退出同步块，计数器值将递减。直到计数器为0,锁被释放。可重入锁锁定的必须得是同一个对象(或者是父类子类对象)。 不要以字符串常量作为锁的对象。因为锁定的是对象。比如说你用到了一个类库，里边锁定了一个”Hello”,而你在你的代码中也锁定了”Hello”,实际上这锁定的是是同一个对象，容易发生死锁。 原子类12345678910111213141516171819202122232425262728293031323334public class Test_11 &#123; AtomicInteger count = new AtomicInteger(0); void m()&#123; for(int i = 0; i &lt; 10000; i++)&#123; /*if(count.get() &lt; 1000)*/ count.incrementAndGet(); &#125; &#125; public static void main(String[] args) &#123; final Test_11 t = new Test_11(); List&lt;Thread&gt; threads = new ArrayList&lt;&gt;(); for(int i = 0; i &lt; 10; i++)&#123; threads.add(new Thread(new Runnable() &#123; @Override public void run() &#123; t.m(); &#125; &#125;)); &#125; for(Thread thread : threads)&#123; thread.start(); &#125; for(Thread thread : threads)&#123; try &#123; thread.join(); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; System.out.println(t.count.intValue()); &#125;&#125; AtoXXX本身的方法是具有原子性的，但是他比synchronized效率要高。 底层实现Java对象头synchronized使用的锁对象是存储在Java对象头里的，jvm中采用2个字来存储对象头(如果对象是数组则会分配3个字，多出来的1个字记录的是数组长度)，其主要结构是由Mark Word 和 Class Metadata Address 组成 。Class Metadata Address存储的是该对象属于类的地址，即可以判断这个对象属于哪一个类。 MarkWord有五种类型： MarkWord： 重量级锁(sychronized)： 锁标识位为10，其中指针指向的是monitor对象（也称为管程或监视器锁）的起始地址。每个对象都存在着一个 monitor 与之关联。只有获取到对象的monitor的线程，才可以执行方法或代码块，其他获取失败的线程会被阻塞，并放入同步队列中，进入BLOCKED状态。 Monitor当我们使用synchronized修饰方法名时，编译后会在方法名上生成一个ACC_SYNCHRONIZED标识来实现同步；当使用synchronized修饰代码块时，编译后会在代码块的前后生成monitorenter和monitorexit字节码来实现同步。 无论使用哪种方式实现，本质上都是对指定对象相关联的monitor的获取，只有获取到对象的monitor的线程，才可以执行方法或代码块，其他获取失败的线程会被阻塞，并放入同步队列中，进入BLOCKED状态。 为了解决线程安全的问题，Java提供了同步机制、互斥锁机制，这个机制保证了在同一问题内只有一个线程能访问共享资源。这个机制的保障来源于监视锁Monitor，每个对象都拥有自己的监视锁Monitor。 Monitor的实现数据结构： 123456789101112131415161718ObjectMonitor() &#123; _header = NULL; _count = 0; _waiters = 0, _recursions = 0; _object = NULL; _owner = NULL; _WaitSet = NULL; _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; FreeNext = NULL ; _EntryList = NULL ; _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ; &#125;复制代码 关键属性： _owner：指向持有ObjectMonitor对象的线程 _WaitSet：存放处于wait状态的线程队列 _EntryList：存放处于等待锁block状态的线程队列 _recursions：锁的重入次数 _count：用来记录该线程获取锁的次数、 ObjectMonitor中有两个队列，_WaitSet 和 _EntryList，用来保存ObjectWaiter对象列表( 每个等待锁的线程都会被封装成ObjectWaiter对象)，_owner指向持有ObjectMonitor对象的线程，当多个线程同时访问一段同步代码时，首先会进入 _EntryList 集合，当线程获取到对象的monitor 后进入 _Owner 区域并把monitor中的owner变量设置为当前线程同时monitor中的计数器count加1，若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入 WaitSe t集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。 若执行线程调用 notify/notifyAll 方法，WaitSet 中的线程被唤醒，进入EntryList 中阻塞，等 待获取锁标记。若执行线程的同步代码执行结束，同样会释放锁标记，monitor 中的_Owner 标记赋值为 null，且计数器赋值为 0 计算。 等待唤醒机制与synchronized所谓等待唤醒机制本篇主要指的是notify/notifyAll和wait方法，在使用这3个方法时，必须处于synchronized代码块或synchronized方法中，否则就会抛出IllegalMonitorStateException异常。 这是因为调用这几个方法前必须拿到当前对象的监视器monitor对象，也就是说notify/notifyAll和wait方法依赖于monitor对象，在前面的分析中，我们知道monitor 存在于对象头的Mark Word 中(存储monitor引用指针)，而synchronized关键字可以获取 monitor ，这也就是为什么notify/notifyAll和wait方法必须在synchronized代码块或者synchronized方法调用的原因。 锁优化锁的状态总共有四种：无锁状态、偏向锁、轻量级锁和重量级锁。随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁。但是不可以降级。 重量级锁sychronized就是重量级锁。 Synchronized是通过对象内部的一个叫做监视器锁（monitor）来实现的。但是监视器锁本质又是依赖于底层的操作系统的Mutex Lock来实现的。而操作系统实现线程之间的切换这就需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized效率低的原因。JDK为了sychronized的优化，引入了轻量级锁和偏向锁。 一个依据：“对于绝大部分的锁，在整个同步周期内都是不存在竞争的。” 这是轻量级锁和偏向锁的依据。 偏向锁在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，因此为了减少同一线程获取锁(会涉及到一些CAS操作,耗时)的代价而引入偏向锁。 偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提供程序的性能。 所以，对于没有锁竞争的场合，偏向锁有很好的优化效果，毕竟极有可能连续多次是同一个线程申请相同的锁。但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。 当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态偏向锁可以提高有同步但竞争比较少的程序性能。 轻量级锁轻量级锁是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。 当尝试获取一个锁对象时，如果锁对象标记为 0 01，说明锁对象的锁未锁定（unlocked）状态。此时虚拟机在当前线程的虚拟机栈中创建 Lock Record，然后使用 CAS 操作将对象的 Mark Word 更新为 Lock Record 指针。如果 CAS 操作成功了，那么线程就获取了该对象上的锁，并且对象的 Mark Word 的锁标记变为 00，表示该对象处于轻量级锁状态。 如果 CAS 操作失败了，虚拟机首先会检查对象的 Mark Word 是否指向当前线程的虚拟机栈，如果是的话说明当前线程已经拥有了这个锁对象，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁。 总结重量级锁通过Monitor来实现，状态转换效率低。 轻量级锁基于CAS来实现。 偏向锁不需要同步，要是同一个线程申请锁。 乐观锁与悲观锁 synchronized是悲观锁，这种线程一旦得到锁，其他需要锁的线程就挂起的情况就是悲观锁。 CAS操作的就是乐观锁，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。 CASAtomic底层的实现就是CAS。 CAS是一个原子操作。 CAS机制当中使用了3个基本操作数：内存地址V，旧的值A，要修改的新值B。 更新一个变量的时候，只有当变量旧的值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B。 这样说或许有些抽象，我们来看一个例子： 1.在内存地址V当中，存储着值为10的变量。 2.此时线程1想要把变量的值增加1。对线程1来说，旧的预期值A=10，要修改的新值B=11。 3.在线程1要提交更新之前，另一个线程2抢先一步，把内存地址V中的变量值率先更新成了11。 4.线程1开始提交更新，首先进行A和地址V的实际值比较（Compare），发现A不等于V的实际值，提交失败。 5.线程1重新获取内存地址V的当前值，并重新计算想要修改的新值。此时对线程1来说，A=11，B=12。这个重新尝试的过程被称为自旋。 6.这一次比较幸运，没有其他线程改变地址V的值。线程1进行Compare，发现A和地址V的实际值是相等的。 7.线程1进行SWAP，把地址V的值替换为B，也就是12。 当多个线程同时使用CAS 操作一个变量时，只有一个会胜出，并成功更新，其余均会失败。失败的线程不会挂起，仅是被告知失败，并且允许再次尝试，当然也允许实现的线程放弃操作。基于这样的原理，CAS 操作即使没有锁，也可以发现其他线程对当前线程的干扰。 Synchronized属于悲观锁，悲观地认为程序中的并发情况严重，所以严防死守。CAS属于乐观锁，乐观地认为程序中的并发情况不那么严重，所以让线程不断去尝试更新。 CAS缺点： CPU开销较大在并发量比较高的情况下，如果许多线程反复尝试更新某一个变量，却又一直更新不成功，循环往复，会给CPU带来很大的压力。 ABA问题。 假设一个变量 A ，修改为 B之后又修改为 A，CAS 的机制是无法察觉的，但实际上已经被修改过了。如果在基本类型上是没有问题的，但是如果是引用类型呢？这个对象中有多个变量，我怎么知道有没有被改过？加个版本号啊。每次修改就检查版本号，如果版本号变了，说明改过，就算你还是 A，也不行。 AtomicReference就是这样做的。 锁消除锁消除是指对于被检测出不可能存在竞争的共享数据的锁进行消除. 主要通过逃逸分析来判定。 何为逃逸？ 当一个对象在方法中被定义后，如果被外部方法所引用，甚至可能会被外部线程所访问到，称为线程逃逸。 如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们的锁进行消除。 因为代码中会有许多隐形的锁，比如String。 锁粗化如果一系列的连续操作都对同一个对象反复加锁和解锁，频繁的加锁操作就会导致性能损耗。 例如在一个for循环里枷锁，就可以把锁提到外面。 自旋锁（空转打圈儿）适用于共享数据只会锁定很短的一段时间。 当获取锁的过程中，未获取到。为了提高效率，JVM 自动执行若干次空循环（while循环中啥也不做），再次申请 锁，而不是进入阻塞状态的情况。称为自旋锁。自旋锁提高效率就是避免线程状态的变更。避免线程挂起导致的花费。 互斥同步对性能影响最大的是阻塞，即线程的挂起和恢复。许多应用中，共享数据的锁定状态只会持续很短的一段时间。如果有两个以上的处理器，能让两个或者以上的线程并行执行，我们就可以让后面请求锁的线程等待一下，但是并不放弃处理器的执行时间。自旋锁的思想是让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。 自旋锁虽然能避免进入阻塞状态从而减少开销，但是它需要进行忙循环操作占用 CPU 时间，它只适用于共享数据的锁定状态很短的场景。 自适应的自旋锁： 自适应的自旋锁意味着自旋的时间不在固定了，而是由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得锁，并且持有者的线程正在运行中，那么虚拟机认为这次自旋也很有可能再次成功，因此会自旋等待较长的时间。相反的是，假如对于某个锁，自旋等待很少成功，那么以后获取这个锁的时候即有可能省略掉这个过程。 一般自旋锁可以搭配CAS来使用。]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统同步互斥]]></title>
    <url>%2F2019%2F10%2F08%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%90%8C%E6%AD%A5%E4%BA%92%E6%96%A5%2F</url>
    <content type="text"><![CDATA[TSL指令类似于java的CAS。 Test and set lock.这是一个原子操作，他的读写操作是不分开的。 TSL指令实现锁机制：当lock为0时，任何进程都可以使用TSL指令将其设置为1，然后访问临界区，操作结束时，再将lock重新设置为0. 1234567void acquire(int *lock)&#123; while(TestAndSet(*lock));&#125;void release(int *lock)&#123; *lock = 0;&#125; 在acquire函数中，如果TestAndSet返回1，那么while循环就一直执行（也就是在这里等待），直到另一个线程调用release。当然，这个实现看起来不太好，主要是等待的线程会不停的检查，浪费CPU，这个问题称之为忙等待（busy-wait or spin-wait），所以这个lock的实现也叫自旋锁spinlock。解决办法是如果需要等待，那么该线程主动交出执行权，让其他线程有机会执行，这种方式称之为让权等待（yield-wait or sleep-wait），应用开发人员使用的互斥锁一都是指这种情况。 以上的这些机制都是忙等待。当一个进程想进入临界区，先检查是否允许进入，若不允许，将会原地等待，直到允许为止。浪费CPU。 信号量可以同时多个线程访问临界区，有P,V两个原子操作。 P(): 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0； V(); 对信号量执行 +1 操作，唤醒睡眠的进程让其完成 P操作。 要是信号量的取值变为了1，那么就变成了互斥量。 1234mutex=new Semaphore(1)mutex.P();临界区mutex.V(); 信号量主要可以解决两类问题。 互斥问题。同一时刻只可以有一个线程访问某一个临界资源。 同步问题。线程A需要等待线程B执行完毕后才可以继续执行。 信号量解决生产者消费者问题 同一时刻，只能有一个生产者或者是消费者访问缓冲区。(互斥问题) 缓冲区满时，生产者需要等待消费者消费。(同步问题) 缓冲区空时，消费者需要等待生产者生产。(同步问题) 123456789101112131415161718192021//互斥量mutex = new Semophore(1);//代表缓冲区有多少产品products = new Semophore(0);//代表缓冲区里有多大位置remainPosition = new Semophore(n);//生产者remainPosition-&gt;P();mutex-&gt;P();Add();mutex-&gt;V();products-&gt;V();//消费者，先去申请产品，在空出一个位置products-&gt;P();mutex-&gt;P();Remove();mutex-&gt;V();remainPosition-V(); 注意，empty-&gt;P()和mutex-&gt;P()不可以交换顺序。 要是 12mutex-&gt;P()empty-P(); 假设我们现在的empty已经是0了，mutex先执行也变为了0，但是当执行到下一步empty-P()，发现自己需要阻塞，但是mutex还未释放，会造成死锁。两个V()操作可以交换顺序。 管程(Monitor)管程=互斥量+条件变量。互斥量：可以保证共享资源在同一时间只能有一个进程访问。条件变量：正在管程内的线程可以放弃对管程的控制权，等待某些条件发生再继续执行。每个条件变量实际上代表的是一个等待队列。当wait时，进程释放锁，挂起，并插入该条件变量的等待队列。signal时，唤醒条件变量等待队列中的进程。 任意时刻管程中只能有一个活跃进程。条件变量：解决死锁问题，挂起进程。条件变量。wait：释放锁，挂起 notify：唤醒等待队列中一个线程。防止死锁。 管程解决生产者消费者问题123456789101112131415161718192021222324252627282930313233mutex buffer;//互斥量，一次只能由一个进程访问int count=0;Condition full,empty;//条件变量//生产者void Produce()&#123; //获取互斥量 mutex.acquire(); //容器满了，线程挂起 while(count==n)&#123; wait(full); &#125; Add c; count++; //唤醒因没有产品挂起的线程 notify(empty); mutex.release();&#125;//消费者void Produce()&#123; //获取互斥量 mutex.acquire(); //容器满了，线程挂起 while(count==0)&#123; wait(empty); &#125; Remove c; count--;//唤醒因容器满了挂起的线程 notify(full); mutex.release();&#125;]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统进程]]></title>
    <url>%2F2019%2F10%2F07%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[进程进程是资源分配的基本单位，他是程序运行时的一个实例。程序运行时，系统会创建一个进程，并分配相关的资源。 程序是静态的，进程是动态的。一个程序可以对应多个进程，一个进程可以包括多个程序。 进程=程序+数据+状态信息。 PCB(进程控制块)每个进程都有一个进程控制块，他是进程的唯一标识。进程块描述进程的基本信息和运行状态。所谓的进程的创建与销毁，就是对PCB的创建与销毁。 各个进程块在内存中应该是以链表的形式存储的，因为进程块需要频繁的进行插入与删除。 进程的生命周期最主要的就是就绪，运行，阻塞三个状态。操作系统创建一个进程完成后，并为其分配了除了cpu之外的所有的资源，那么进程进入就绪(ready)状态，当CPU处于空闲的时候，就绪状态的进程占用CPU，进入运行（running）状态。正在执行的进程，由于等待某个事件发生而无法执行时，便放弃CPU而处于阻塞（waiting）状态。 ready-&gt;running当没有其他进程占用CPU，所有的ready进程就可以去竞争CPU，获得CPU的进程进入running状态。 running-&gt;waiting正在执行的进程，因为等待某个事件发生而放弃CPU时，进入waiting状态。比如I/O阻塞，申请缓冲区不能满足、等待信件等。 running-&gt;ready处于执行状态的进程在其执行过程中，因分配给它的一个时间片已用完或更高优先级的进程抢占而不得不让出处理机，于是进程从执行状态转变成就绪状态。 waiting-&gt;ready当等待事件完成的时候，从阻塞进入就绪态。需要正在运行的进程对他唤醒。 进程切换因为所有的进程都有自己独立的地址空间。 页表以及地址空间的切换。 寄存器，程序计数器，堆栈的切换。 进程上下文切换过程： 保存现场。暂停当前进程，从运行态变为其他状态，保存当前进程的上下文，包括CPU寄存器状态，程序计数器状态等。保存在PCB中。 选取进程。调度另一个进程从就绪转为运行。 恢复现场。从内存中恢复下一个要执行的进程的上下文，恢复该进程原来的状态到寄存器，恢复程序执行上一次暂停的地方。从PCB中取。 在进程切换的过程中，页表会改变，地址空间会改变，高速缓存中的存储的数据过期，也需要进行切换。 进程挂起将进程从内存转移到磁盘上。进程挂起状态包括阻塞挂起（在外存，处于阻塞）和就绪挂起（在外存，就绪状态）。 进程挂起状态转换： 阻塞到阻塞挂起。内存不够时，将阻塞状态的进程移到外存，变为阻塞挂起状态。 就绪到就绪挂起。有高优先级阻塞和低优先级就绪，那么将低优先级挂起。 运行到就绪挂起。 挂起是将进程从内存转移到磁盘，而阻塞是由于资源得不到满足暂时无法获取CPU，还是在内存的。 状态队列操作系统中维护了多个队列，不同的队列来表示不同的状态。就绪队列，阻塞队列，运行队列等。方便操作系统管理进程。 线程当我们并发的需求时，如果采用多进程的话，因为进程每个进程都有自己的独立空间，进程间通信麻烦，还有进程切换的时候需要进行保护现场恢复现场，十分耗费资源，效率低下。于是，引入了线程。 线程是轻量级的进程。所有的线程共享进程的地址空间，进程间开销小，通信方便。进程中的所有线程共享代码，文件等资源。但是，他们都有自己的堆栈，寄存器等。 进程是资源分配的角色，线程是执行功能的角色。一个线程崩溃，整个进程崩溃。因此，在对于安全性过高的场合，我们一般使用进程来解决并发问题。比如说，我们的浏览器，每开一个界面，就创建一个进程。 OS中两种线程根据操作系统能够感知到线程，分为用户线程以及内核线程。 内核线程内核完成线程的创建以及管理。内核分配CPU是以线程为单位的。 优点： 一个线程阻塞不会导致整个进程阻塞。 内核会为每一个线程分配CPU，对于多线程的进程，时间片时间大大增加。 缺点： 线程切换要从用户态转移到内核态，耗费大，速度慢。 用户线程用户级的线程库完成线程的创建以及管理。内核资源的分配仍然是按照进程（用户进程）进行分配的。不依赖于操作系统的内核，操作系统感受不到用户线程的存在。 缺点： 因此，对于操作系统来说，这个用户线程所属的进程是没有线程的，因此，一个线程的阻塞将导致整个进程的阻塞，因为，对于操作系统来说，他看到的只是这个进程，这个用户线程阻塞，对操作系统来说就是整个进程阻塞，所以这个进程将会阻塞。 因为没有操作系统的管制，一个用户线程拿到了分配给这个进程的时间片，他会一直霸占着，除非她主动放弃，或者到这个时间片结束，可能会导致别的用户线程没有机会执行。 优点： 但是，用户线程切换不需要从用户态转到内核态，消耗小，速度快。 总的来说，对于用户线程，操作系统是感受不到，还是会把它看作一个进程来进行处理。 内核线程与用户线程 多线程模型将用户线程与内核线程绑定。主要有一对一，多对一，以及多对多。操作系统中主要使用多对多。 多对一多个用户线程与一个内核线程绑定。 缺点是一个线程阻塞，这多个用户线程都会被阻塞。 一对一一个用户线程绑定一个内核线程。 缺点是每创建一个用户级线程都需要创建一个内核级线程与其对应，这样创建线程的开销比较大，会影响到应用程序的性能。 多对多将 n 个用户级线程映射到 m 个内核级线程上，要求 m &lt;= n。 不会出现一个用户线程阻塞，所有线程都阻塞的情况。 详解多线程模型 与进程区别 进程是资源分配的最小单位，线程是程序执行的最小单位。 进程有自己的独立空间，每创建一个进程，都要为他分配独立的地址空间，花费很大。而线程是共享进程地址空间的，花费要小很多。 进程之间的通信需要以通信的方式（IPC)进行，需要通过内核来通信。而线程可以通过共享变量等方式进行。 进程之间切换时间比线程之间切换时间要大得多。因为进程之间页表是不同的，需要切换页表，开销比较大。因为各个进程页表不同，TLB，缓存信息可能都需要重新加载。而线程是共享的。 一个进程死掉，对其他进程没有影响；一个线程死掉，整个进程就会崩溃。当一个线程向非法地址读取或者写入，无法确认这个操作是否会影响同一进程中的其它线程，所以只能是整个进程一起崩溃。 线程切换与进程上下文切换不同的是，线程上下文切换没有页表以及地址空间的切换，因为同一个进程的线程共享同一个地址空间。只需要进行程序计数器，寄存器，以及线程的堆栈的切换。 fork and execlinux的fork 和exec 函数。 fork() 复制出一个子进程，这个进程几乎是当前进程的一个拷贝：子进程和父进程使用相同的代码段；子进程复制父进程的堆栈段和数据段。这样，父进程的所有数据都可以留给子进程，但是，子进程一旦开始运行，虽然它继承了父进程的一切数据，但实际上数据却已经分开，相互之间不再有影响了，也就是说，它们之间不再共享任何数据了。它们再要交互信息时，只有通过进程间通信来实现，这将是我们下面的内容。既然它们如此相象，系统如何来区分它们呢？这由函数的返回值来决定的。对于父进程， fork函数返回了子程序的进程号，而对于子程序，fork函数则返回零。在操作系统中，我们用ps函数就可以看到不同的进程号，对父进程而言，它的进程号是由比它更低 层的系统调用赋予的，而对于子进程而言，它的进程号即是fork函数对父进程的返回值。在程序设计中，父进程和子进程都要调用函数fork（）下面的代码，而我们就是利用fork（）函数对父子进程的不同返回值用if…else…语句来实现让父子进程完成不同的功能。 exec将替换现有进程，执行exec的程序。 一个进程一旦调用exec类函数，它本身就”死亡”了，系统把代码段替换成新的程序的代码，废弃原有的数据段和堆栈段，并为新程序分配新的数据段与堆栈段，唯一留下的，就是进程号，也就是说，对系统而言，还是同一个进程，不过已经是另一个程序了。 僵尸进程和孤儿进程正常情况下，子进程是通过父进程创建的，子进程在创建新的进程。子进程的结束和父进程的运行是一个异步过程,即父进程永远无法预测子进程 到底什么时候结束。 一个子进exit()之后，内核释放该进程所有的资源,包括打开的文件,占用的内存等。 但是仍然为其保留一定的信息(包括进程号the process ID,退出状态the termination status of the process,运行时间the amount of CPU time taken by the process等)。直到父进程通过wait / waitpid来取时才释放。这样，一个进程才算是完全终止掉。 当一个父进程迟迟没有调用wait()，这个子进程内存中保存的信息就迟迟不会释放，包括进程号也不会释放，操作系统的进程号是有限的，因此僵尸进程的危害很大。 当一个父进程退出，子进程还在运行，那么子进程将会称为孤儿进程。孤儿进程会被init进程处理，使用wait()完成进程的终止等，因此，孤儿进程是没有坏处的。 孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。 僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统概述]]></title>
    <url>%2F2019%2F10%2F07%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[什么是操作系统操作系统主要进行应用程序管理，资源管理，外设管理等工作。 在操作系统中，将CPU抽象为进程，将内存抽象为地址空间，将磁盘抽象为文件。 OS=shell+kernel.shell就是GUI或者是命令行。Kernel是操作系统的核心。 kernel主要完成的工作包括CPU调度，物理内存虚拟内存的管理，文件系统的管理，中断处理，外设管理等。 kernel的特征： 并发（应用并发执行）。 共享。某一个公共资源是可以共享访问的还是互斥访问的。 虚拟化。将物理实体虚拟化为逻辑实体。主要包括时分复用(时间片)和空分复用(虚拟内存)。 异步。 OS启动过程Disk：存储bootloader以及OS.BIOS:基本IO处理系统。 最先放入内存的是BIOS启动固件。BIOS的第一步是检测外设，完成后，将bootloader加载进内存，并且CPU控制权转交给bootloader，bootloader再将磁盘上的OS加载进内存，这是OS掌控CPU。 BIOS—&gt;加载bootloader—&gt;加载OS。（所以说我们安装系统的时候要先进入BIOS设置启动项，这个启动项就是bootloader）。 系统调用，中断，异常都需要从用户态转移到内核态。 中断机制来源于外设。 为了支持CPU 和设备之间 的 并行操作。当IO事件完成之后，设备中断通知CPU，CPU在进行相应事件的处理。可以看作是一种异步操作啊。 当CPU 启动设备进行输入/输出后 ，设备便可以独立工作，CPU 转去处理与此次输入/输出不相关的 事情；当设备完成输入/输出后，通过向CPU 发中断报告此次 输入/输出的结果，让CPU 决定如何处理以后的事情。 中断过程 设备（硬件）将中断事件的ID传递给中断寄存器。不同的中断ID范围代表不同的中断类型。 CPU在执行完一条指令后，会查看中断寄存器，假如有中断的话，进行中断处理。 CPU保存现场。保存各种寄存器等。 CPU 根据中断码查中断向量表，获得与该中断相关的处理程序的入口地址。 进行相应中断处理。 恢复之前保存的处理状态。 异常来源于应用程序。CPU执行指令非法。 异常过程与中断过程差不多，也是保存现场，处理，恢复现场这几个过程。 但是不同的是，异常一般是交给进程自己来处理，而中断是由内核的中断函数来处理，根据不同的中断类型执行不同的中断函数。 系统调用当应用程序需要调用系统级别的函数请求。 系统调用过程 每一个系统调用对应一个系统调用号。 根据系统调用号选取相应的系统调用例程进行系统调用。 返回系统调用结果。 系统调用需要从用户态切换到内核态。 总结系统调用，中断，异常机制其实都是大同小异。在操作系统中都维持着一个表，中断是中断号和中断函数对应，系统调用是系统调用号和系统调用函数，根据ID去调用相应的函数，返回结果。 而且OS都需要从用户态转到内核态。]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IO线程模型]]></title>
    <url>%2F2019%2F09%2F30%2FIO%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[阻塞I/O 每一条连接都需要建立一个独立的线程来处理，机器耗费线程资源。 当没有数据读写时，线程还会阻塞。 Reactor模式IO多路复用+线程池来实现。I/O多路复用来解决会有多个线程阻塞的问题，IO多路复用只会造成一个线程阻塞。线程池不必为每个连接都建立一个新的线程。 Reactor模型，是指通过一个或多个输入同时传递给服务处理器的服务请求的事件驱动处理模式。 服务端程序处理传入多路请求，并将它们同步分派给请求对应的处理线程，Reactor模式也叫Dispatcher模式，即I/O多路复用统一监听事件，收到事件后分发(Dispatch给某进程)。 Reactor两个关键组成： Reactor负责监听和分发事件，分发给适当的处理程序来对IO事件做出反应。 Handler处理程序执行I/O事件要完成的实际事件.单Reactor Reactor对象通过select不断轮询监控客户端请求事件，收到事件后通过dispatch进行分发 如果是建立连接请求事件，则由Acceptor通过accept处理连接请求，然后创建一个Handler对象处理连接完成后的后续业务处理 如果不是建立连接事件，则Reactor会分发调用连接对应的Handler来响应 Handler会完成read-&gt;业务处理-&gt;send的完整业务流程单Reactor多线程主要通过建立一个线程池。Worker线程池会分配独立的线程完成真正的业务处理，如何将响应结果发给Handler进行处理。 主从Reactor多线程 Reactor主线程MainReactor对象通过select监控建立连接事件，收到事件后通过Acceptor接收，处理建立连接事件。 Accepto处理建立连接事件后，MainReactor将Socket分配Reactor子线程给SubReactor进行处理。 SubReactor将Socket加入连接队列进行监听，并创建一个Handler用于处理各种连接事件，例如读写操作。 当有新的事件发生时，SubReactor会调用连接对应的Handler进行响应 Handler通过read读取数据后，会分发给后面的Worker线程池进行业务处理 Worker线程池会分配独立的线程完成真正的业务处理，如何将响应结果发给Handler进行处理 Handler收到响应结果后通过send将响应结果返回给clientNIO代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142package nioDemo; import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.CharBuffer;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.nio.channels.ServerSocketChannel;import java.nio.channels.SocketChannel;import java.nio.charset.Charset;import java.util.Iterator;import java.util.Random;import java.util.Set; /*服务器端，:接收客户端发送过来的数据并显示， *服务器把上接收到的数据加上"echo from service:"再发送回去*/public class ServiceSocketChannelDemo &#123; public static class TCPEchoServer implements Runnable&#123; /*服务器地址*/ private InetSocketAddress localAddress; public TCPEchoServer(int port) throws IOException&#123; this.localAddress = new InetSocketAddress(port); &#125; @Override public void run()&#123; ServerSocketChannel ssc = null; Selector selector = null; Random rnd = new Random(); try &#123; /*创建选择器*/ selector = Selector.open(); /*创建服务器通道*/ ssc = ServerSocketChannel.open(); ssc.configureBlocking(false); /*设置监听服务器的端口，设置最大连接缓冲数为100*/ ssc.bind(localAddress, 100); /*服务器通道只能对tcp链接事件感兴趣*/ ssc.register(selector, SelectionKey.OP_ACCEPT); &#125; catch (IOException e1) &#123; System.out.println("server start failed"); return; &#125; System.out.println("server start with address : " + localAddress); /*服务器线程被中断后会退出*/ try&#123; while(!Thread.currentThread().isInterrupted())&#123; int n = selector.select(); if(n == 0)&#123; continue; &#125; Set&lt;SelectionKey&gt; keySet = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; it = keySet.iterator(); SelectionKey key = null; while(it.hasNext())&#123; key = it.next(); /*防止下次select方法返回已处理过的通道*/ it.remove(); /*若发现异常，说明客户端连接出现问题,但服务器要保持正常*/ try&#123; /*ssc通道只能对链接事件感兴趣*/ if(key.isAcceptable())&#123; /*accept方法会返回一个普通通道， 每个通道在内核中都对应一个socket缓冲区*/ SocketChannel sc = ssc.accept(); sc.configureBlocking(false); /*向选择器注册这个通道和普通通道感兴趣的事件，同时提供这个新通道相关的缓冲区*/ int interestSet = SelectionKey.OP_READ; sc.register(selector, interestSet, new Buffers(256,256)); System.out.println("accept from"+ sc.getRemoteAddress()); &#125; /*（普通）通道感兴趣读事件且有数据可读*/ if(key.isReadable())&#123; /*通过SelectionKey获取通道对应的缓冲区*/ Buffers buffers = (Buffers)key.attachment(); ByteBuffer readBuffer = buffers.getReadBuffer(); ByteBuffer writeBuffer = buffers.gerWriteBuffer(); /*通过SelectionKey获取对应的通道*/ SocketChannel sc = (SocketChannel) key.channel(); /*从底层socket读缓冲区中读入数据*/ sc.read(readBuffer); readBuffer.flip(); /*解码显示，客户端发送来的信息*/ CharBuffer cb = utf8.decode(readBuffer); System.out.println(cb.array()); readBuffer.rewind(); /*准备好向客户端发送的信息*/ /*先写入"echo:"，再写入收到的信息*/ writeBuffer.put("echo from service:".getBytes("UTF-8")); writeBuffer.put(readBuffer); readBuffer.clear(); /*设置通道写事件*/ key.interestOps(key.interestOps() | SelectionKey.OP_WRITE); &#125; /*通道感兴趣写事件且底层缓冲区有空闲*/ if(key.isWritable())&#123; doSomething(); &#125; &#125;catch(IOException e)&#123; System.out.println("service encounter client error"); /*若客户端连接出现异常，从Seletcor中移除这个key*/ key.cancel(); key.channel().close(); &#125; &#125; Thread.sleep(rnd.nextInt(500)); &#125; &#125;catch(InterruptedException e)&#123; System.out.println("serverThread is interrupted"); &#125; catch (IOException e1) &#123; System.out.println("serverThread selecotr error"); &#125;finally&#123; try&#123; selector.close(); &#125;catch(IOException e)&#123; System.out.println("selector close failed"); &#125;finally&#123; System.out.println("server close"); &#125; &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException, IOException&#123; Thread thread = new Thread(new TCPEchoServer(8080)); thread.start(); Thread.sleep(100000); /*结束服务器线程*/ thread.interrupt(); &#125; &#125; Proactor模型（异步）主要的核心在于回调机制。Reactor在接收事件后需要交给Reactor处理。而Proactor直接由操作系统来处理相关事件，然后返回结果。 理解高性能网络模型]]></content>
      <categories>
        <category>IO</category>
      </categories>
      <tags>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[I/O模型]]></title>
    <url>%2F2019%2F09%2F29%2FIO%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Socket与ServerSocket网络通信需要一对socket，即通信的两端各有一个socket，两个socket之间形成一个管道，进行数据流的通信。ServerSocketServerSocket监听服务器端的一个端口，当一个客户端发送来连接时，ServerSocket来处理连接，成功后返回一个常规的Socket对象，用来与客户端socket进行数据传输。 同步 异步 阻塞 非阻塞同步与异步主要是从消息通知机制角度来说的。当一个同步调用发出后，调用者要一直等待返回消息（结果）后，才能进行后续的执行；当一个异步过程调用发出后，调用者不能立刻得到返回消息（结果），实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。异步是调用完成后由别人来通知他。 阻塞与非阻塞主要是程序（线程）等待消息通知时的状态角度来说的。阻塞调用是指调用结果返回之前，当前线程会被挂起，一直处于等待消息通知，不能够执行其他业务。非阻塞和阻塞的概念相对应，指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。如果在这个等待的过程中，等待者除了等待消息通知之外不能做其它的事情，那么该机制就是阻塞的。 阻塞与同步是不同的。如果这个线程在等待函数返回时，仍在执行其他消息处理，那么这就是同步非阻塞。如果这个线程在等待函数返回时，没有执行其他消息处理，而是挂起等待，那么就是同步阻塞 概念说明操作系统将内存空间分为了内核空间和用户空间。进程切换非常的耗资源，所以能不挂起进程就不挂起进程。将进程阻塞是让出CPU资源。 对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段：1. 等待数据准备 (Waiting for the data to be ready)2. 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) Linux IO的五种模型阻塞IO 当应用进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在进程这边，整个应用进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，应用进程才解除block的状态，重新运行起来。在内核执行I/O的两个阶段，都是阻塞的。每个连接都需要配套一个线程，不适合高并发的情况。 在阻塞的过程中，这个线程被挂起了，但是他让出了CPU，其他应用进程可以继续占用CPU执行。 非阻塞IO基于轮询的方式。当所请求的I/O操作不能满足要求时候，不把本进程投入睡眠，而是返回一个错误。也就是说当数据没有到达时并不等待，而是以一个错误返回。并且进程会多次轮询的请求I/O操作。应用程序的线程需要不断的进行 I/O 系统调用，轮询数据是否已经准备好，如果没有准备好，继续轮询，直到完成系统调用为止 。这样，好处是线程不需要一直阻塞，但是需要不断地进行I/O系统调用，不断轮询，浪费CPU。不断发起I/O操作及其浪费CPU资源。同步非阻塞就是 “每隔一会儿瞄一眼进度条” 的轮询（polling）方式。需要注意，拷贝数据整个过程，进程仍然是属于阻塞的状态。 I/O多路复用基于操作系统的poll，select，epoll。非阻塞IO问题：由于同步非阻塞方式需要不断主动轮询，轮询占据了很大一部分过程，轮询会消耗大量的CPU时间，但是服务器端可能会有多个连接，这样他对每一个连接都这样做，要是连接数量太多时，是不适合的。 IO多路复用有两个特别的系统调用select、poll、epoll函数。select调用是内核级别的，select轮询相对非阻塞的轮询的区别在于—前者可以等待多个socket，能实现同时对多个IO端口进行监听，当其中任何一个socket的数据准好了，就能返回进行可读，然后进程再进行recvform系统调用，将数据由内核拷贝到用户进程，当然这个过程是阻塞的。 select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。 这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这两个函数可以同时阻塞多个I/O操作（只需要阻塞一个select函数）。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时（注意不是全部数据可读或可写），才真正调用I/O操作函数。 上面的图和blocking IO的图其实并没有太大的不同，在两个阶段都需要阻塞。当连接数量很少的时候，I/O多路复用可能比BIO效率还要低，因为I/O多路复用需要多执行一个select内核操作。但是I/O多路复用的优势在于他可以处理更多的连接，而不是处理单个连接速度更快。与传统的多线程/多进程模型比，I/O多路复用的最大优势是系统开销小，系统不需要创建新的额外进程或者线程，也不需要维护这些进程和线程的运行，降底了系统的维护工作量，节省了系统资源。 信号驱动IO在信号驱动式I/O模型中，应用程序使用套接口进行信号驱动I/O，并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。 基本不怎么用。 异步IO用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知（回调函数）。IO两个阶段，进程都是非阻塞的。 异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。 总结注意：同步非阻塞I/O和I/O多路复用，在返回可读条件后，都需要再调用一次I/O操作，进行复制数据。首先一个IO操作其实分成了两个步骤：发起IO请求和实际的IO操作，同步IO和异步IO的区别就在于第二个步骤是否阻塞，如果实际的IO读写阻塞请求进程，那么就是同步IO，因此阻塞IO、非阻塞IO、IO复用、信号驱动IO都是同步IO，如果不阻塞，而是操作系统帮你做完IO操作再将结果返回给你，那么就是异步IO。阻塞IO和非阻塞IO的区别在于第一步，发起IO请求是否会被阻塞，如果阻塞直到完成那么就是传统的阻塞IO，如果不阻塞，那么就是非阻塞IO。 select poll epoll目前支持I/O多路复用的系统调用有 select，poll，epoll，I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。select，pselect，poll，epoll本质上都是同步I/O。 文件描述符用于表述指向文件的引用的抽象化概念。。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。 Linux的socket事件wakeup callback机制linux wakeup callback机制是IO多路复用的本质。 Linux通过socket睡眠队列来管理所有等待socket的某个事件的进程（Process），同时通过wakeup机制来异步唤醒整个睡眠队列上等待事件的Process，通知Process相关事件发生。 每个socket维护了一个队列，比如socket可读的时候，内核就会唤醒队列里的各个Process，并且执行每个Process的callback函数。 每一个socket都有sleep_list,当某个进程所关心的事件在socket中并没有发生，那么将进程插入到sleep_list，当socket的时间发生了，那么就去遍历他sleep_list中的每个进程的callback函数。 select我们以read事件为例子。当socket上所监听的事件发生了，那么相应的进程就去处理。那么怎么获取监听的事件发生呢？我们应该block在等待事件的发生上，这个事件简单点就是关心的N个socket中一个或多个socket有数据可读了，当block解除的时候，就意味着，我们一定可以找到一个或多个socket上有可读的数据。 根据wakeup callback。所以，进程需要同时插入到我们管理的这好多个socket的sleep_list上等待任意一个socket可读事件发生而被唤醒，当Process被唤醒的时候，其callback里面应该有个逻辑去检查具体哪些socket可读了。 举个例子：假设c1，c2，c3连接到了服务器端，我们想监听他们的读事件，因此我们将进程p1插入到他们与服务器各自的socket中sleep_list中去，此时没有事件发生，因此进程处于睡眠状态，当c1客户端发送来了数据，有数据读取的时候，p1进程被唤醒。伪代码： 123456789private int sk_event;void poll() &#123; //其他逻辑... when (receive queue is not empty) &#123; sk_event |= POLL_IN； &#125; //其他逻辑...&#125; 当receive queue不为空的时候（即收到了消息），我们就给这个socket的sk_event添加一个POLL_IN事件，用来表示当前这个socket可读。将来Process遍历到这个socket，发现其sk_event包含POLL_IN的时候，就可以对这个socket进行读取数据操作了。 接下来，p1执行select，select会将需要监控的readfds集合拷贝到内核空间（因为内核才能通知说某个socket可读），然后遍历自己监控的socket，挨个调用socket的poll逻辑以便检查该socket是否有可读事件。遍历完所有的socket后，如果没有任何一个sk可读，那么select会调用schedule，使得Process进入睡眠（或者睡眠timeout这么长时间）。如果在timeout时间内某个socket上有数据可读了，或者等待timeout了，则调用select的Process会被唤醒。伪代码如下： 12345for (socket in readfds) &#123; sk_event.evt = socket.poll(); sk_event.sk = socket; return_event_for_process;&#125; 1int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。select缺点：1.文件描述符的数量存在最大限制，在Linux上一般为1024。 2.对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低。每次select()都需要扫描所有的fd_set。而epoll是通过注册回调函数来实现的，所以epoll效率大大高于select. 3.需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。 poll解决了文件描述符数量限制的情况。 1int poll (struct pollfd *fds, unsigned int nfds, int timeout); poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。与select两点区别：1.文件描述符大小不限制。2.不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。 12345struct pollfd &#123; int fd; /* file descriptor */ short events; /* requested events to watch */ short revents; /* returned events witnessed */&#125;; pollfd结构包含了要监视的event和发生的event。 epoll解决了需要循环遍历文件描述符的缺点，解决了需要将大量的fds从内核拷贝到用户空间的问题。 将大量的fds从内核拷贝到用户空间的解决：共享内存。epoll通过内核与用户空间mmap同一块内存来解决。mmap将用户空间的一块地址和内核空间的一块地址同时映射到相同的一块物理内存地址（不管是用户空间还是内核空间都是虚拟地址，最终要通过地址映射映射到物理地址），使得这块物理内存对内核和对用户均可见，减少用户态和内核态之间的数据交换。 需要循环遍历文件描述符的解决：epoll引入了一个中间层，一个双向链表ready_list，一个单独的睡眠队列single_epoll_wait_list。1.调用epoll之前，我们希望我们的MyProcess可以管理四个socket。2.四个socket都没有事件，这时候MyProcess进入single_epoll_wait_list并且sleep。3.有一个socket（大红色）收到了数据，触发其wait_entry_sk，把这个socket加入到ready_list里。4.MyProcess被唤醒（从single_epoll_wait_list出来了表示被唤醒），来处理ready_list中的所有socket：遍历epoll的ready_list，挨个调用每个socket的poll逻辑收集发生的事件，对于监控可读事件而已，ready_list上的每个socket都是有数据可读的，这里的遍历必要的。 epoll有两种工作模式，LT和ET。LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。 ServerSocket与SocketLinux 五种IO模型select、poll、epoll详解Linux IO模式及 select、poll、epoll详解深入理解select，poll，epoll]]></content>
      <categories>
        <category>IO</category>
      </categories>
      <tags>
        <tag>IO</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程]]></title>
    <url>%2F2019%2F09%2F29%2FJava%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[并发作用将多核CPU的计算能力发挥到极致，性能得到提升。 面对复杂业务模型，并行程序会比串行程序更适应业务需求，而并发编程更能吻合这种业务拆分。 并发缺点 线程安全问题。 频繁的上下文切换。 概念并发与并行Concurrency is about dealing with lots of things at once. Parallelism is about doing lots of things at once。并发指的是多个任务交替进行，而并行则是指真正意义上的“同时进行”。实际上，如果系统内只有一个CPU，而使用多线程时，那么真实系统环境下不能并行，只能通过切换时间片的方式交替进行，而成为并发执行任务。真正的并行也只能出现在拥有多个CPU的系统中。 同步与异步主要从消息通知角度来看。 同步是说在调用一个函数后，直到执行完成才返回结果。 异步是在调用一个函数之后，立即返回，等待函数执行完成之后，通过状态、通知和回调来通知调用者。 阻塞与非阻塞主要从等待返回结果时的状态来看。 阻塞就是在等待返回结果时，当前线程会被挂起，让出CPU，不能执行其他业务。 非阻塞就是在等待返回结果时，当前线程不会阻塞，可以去执行其他的业务。 临界区资源临界区用来表示一种公共资源或者说是共享数据，可以被多个线程使用。但是每个线程使用时，一旦临界区资源被一个线程占有，那么其他线程必须等待。 线程创建线程 继承Thread 实现Runnable 实现Callable 123456789101112131415161718192021222324252627282930313233// extends thread Thread t1 = new Thread()&#123; @Override public void run() &#123; System.out.println("t1"); &#125; &#125;; t1.start(); // implements Runnable Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("t2"); &#125; &#125;); t2.start(); // implements Callable,Callable可以有返回值 ExecutorService service=Executors.newSingleThreadExecutor(); Future&lt;String&gt; future=service.submit(new Callable() &#123; @Override public String call() throws Exception &#123; return "thread 3"; &#125; &#125;); try &#123; String result=future.get(); System.out.println(result); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; 线程状态 新建(new)，创建线程。 Runnable。包括Running和Ready两个阶段，Running就是占用CPU运行，Ready是线程还处于等待阶段。 阻塞(Blocked)。等待获取临界区资源，一旦他获得了锁就会结束这个状态。 无限期等待(Waiting)。 等待其它线程显式地唤醒，否则不会被分配 CPU 时间片。 进入方法 退出方法 没有设置 Timeout 参数的 Object.wait() 方法 Object.notify() / Object.notifyAll() 没有设置 Timeout 参数的 Thread.join() 方法 被调用的线程执行完毕 LockSupport.park() 方法 LockSupport.unpark(Thread) 限期等待(Timed-waiting)。 无需等待其它线程显式地唤醒，在一定时间之后会被系统自动唤醒。 进入方法 退出方法 Thread.sleep() 方法 时间结束 设置了 Timeout 参数的 Object.wait() 方法 时间结束 / Object.notify() / Object.notifyAll() 设置了 Timeout 参数的 Thread.join() 方法 时间结束 / 被调用的线程执行完毕 LockSupport.parkNanos() 方法 LockSupport.unpark(Thread) LockSupport.parkUntil() 方法 LockSupport.unpark(Thread) 终止。线程任务结束，或者是产生了异常而终止。 线程基本操作sleep() and wait()sleep会休眠当前线程，等到了时间，自动苏醒。 调用 wait() 使得线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。 两者区别： sleep到点自己醒，wait需要其他线程调用notify来唤醒。 wait()方法必须要在同步方法或者同步块中调用，也就是必须已经获得对象锁。 sleep不释放锁，wait释放锁。 join()在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。 对于以下代码，虽然 b 线程先启动，但是因为在 b 线程中调用了 a 线程的 join() 方法，b 线程会等待 a 线程结束才继续执行，因此最后能够保证 a 线程的输出先于 b 线程的输出。 yield()一旦执行，当前线程会让出cpu，但是，需要注意的是，让出的CPU并不是代表当前线程不再运行了，如果在下一次竞争中，又获得了CPU时间片当前线程依然会继续运行。另外，让出的时间片只会分配给当前线程相同优先级的线程。 sleep()和yield()方法，同样都是当前线程会交出处理器资源，而它们不同的是，sleep()交出来的时间片其他线程都可以去竞争，也就是说都有机会获得当前线程让出的时间片。而yield()方法只允许与当前线程具有相同优先级的线程能够获得释放出来的CPU时间片。 守护线程守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。 当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。 main() 属于非守护线程。 使用 setDaemon() 方法将一个线程设置为守护线程 线程中断问题线程可以调用interrupt()来中断别的线程。但这个操作并不一定会使线程中断，更像是给了线程一个通知，但具体是否中断还是要看线程本身。 InterruptedException通过调用一个线程的 interrupt() 来中断该线程，如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。 interrupted()如果线程不处在等待或者是阻塞状态，那么直接interrupt是不能中断线程的。但是调用 interrupt() 方法会设置线程的中断标记，此时调用 interrupted() 方法会返回 true。 这样，线程就可以对相应的中断请求进行处理了。 123456789101112131415161718public class Test2 &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub Thread t1=new Thread() &#123; @Override public void run() &#123; // TODO Auto-generated method stub while(!isInterrupted()) &#123; &#125; System.out.println("end......."); &#125; &#125;; t1.start(); t1.interrupt(); System.out.println(t1.isInterrupted()); &#125;]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM字节码执行引擎]]></title>
    <url>%2F2019%2F09%2F25%2F%E5%AD%97%E8%8A%82%E7%A0%81%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[方法调用方法调用就是确定调用哪一个方法。 在编译阶段，即将java文件转化为class文件，class文件中存储的是方法的符号引用(类似于一个代号吧)，而不是直接引用(内存地址)，因为类还没有加载到内存嘛，所以具体的内存地址肯定是不知道的。 因此，需要到类加载期间，甚至是运行期间才可能确定目标方法的直接引用。 在类加载的阶段，会将一部分符号引用转化为直接引用，前提是 方法在程序运行前就可以确定他是哪一个。 比如说private和static两类方法，这是因为这两类方法都不可能被继承或者是被重写，只可能有唯一的版本。别的方法就有可能被重写，存在多个版本，难以确定。 除了这两类，还有构造方法以及final方法，这几个都是不可能被重写的，可以唯一确定。 所以，私有方法，final方法，构造方法，static方法在编译期间既可以完全确定，在类加载阶段直接将符号引用转化为直接引用，其他方法都是在运行期间才能确定。 分派重载和重写在JVM中是如何实现的？ 静态分派重载的实现。 重载时是通过参数的静态类型而不是实际类型决定使用哪个重载函数。 所以，重载的实现需要参数类型或者个数不同。 12//Father是静态类型 ， Son是实际类型。Father father = new Son(); 所以，在编译阶段就可以确定重载的函数是哪一个。 12345678910111213141516 void test() &#123; Father father = new Son(); //静态分派 print(father); &#125; void print(Father father) &#123; System.out.println("this is father"); &#125; void print(Son son) &#123; System.out.println("this is son"); &#125;/*输出：this is father**/ 动态分派重写的实现。 在运行阶段才可以确定重写的函数是哪一个。 1234567891011121314151617181920212223242526public class DynamicDispatch &#123; static abstract class Human&#123; protected abstract void sayHello(); &#125; static class Man extends Human&#123; @Override protected void sayHello() &#123; System.out.println("man say hello!"); &#125; &#125; static class Woman extends Human&#123; @Override protected void sayHello() &#123; System.out.println("woman say hello!"); &#125; &#125; public static void main(String[] args) &#123; Human man=new Man(); Human woman=new Woman(); man.sayHello(); woman.sayHello(); man=new Woman(); man.sayHello(); &#125;&#125; 我们从invokevirtual指令的多态查找过程开始说起，invokevirtual指令的运行时解析过程大致分为以下几个步骤： 1、找到操作数栈顶的第一个元素所指向的对象的实际类型，记作C。2、如果在类型C中找到与常量中的描述符和简单名称相符合的方法，然后进行访问权限验证，如果验证通过则返回这个方法的直接引用，查找过程结束；如果验证不通过，则抛出java.lang.IllegalAccessError异常。3、否则未找到，就按照继承关系从下往上依次对类型C的各个父类进行第2步的搜索和验证过程。4、如果始终没有找到合适的方法，则跑出java.lang.AbstractMethodError异常。 由于invokevirtual指令执行的第一步就是在运行期确定接收者的实际类型，所以两次调用中的invokevirtual指令把常量池中的类方法符号引用解析到了不同的直接引用上，这个过程就是Java语言方法重写的本质。我们把这种在运行期根据实际类型确定方法执行版本的分派过程称为动态分派。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM垃圾收集机制]]></title>
    <url>%2F2019%2F09%2F21%2FJVM%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[GC需要完成三件事： 哪些对象需要回收？ 何时进行回收？ 怎么样回收？ 哪些对象需要回收死掉的对象需要回收。 如何判断对象已死？可达性分析算法+finalize(). 可达性分析把一系列称为”GC Roots”的对象作为起点，向下进行搜索，当GC Roots到某个对象不可达时，这个对象就是可回收的。 GC Roots对象包括： 虚拟机栈中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中引用的对象。 为什么不使用引用计数法呢？ 引用计数法就是每当加了一个引用，引用计数器加一，一个引用失效，引用计数器减一，引用计数器为零时该对象死亡。 但是引用计数无法解决的是循环引用的问题。 循环引用： 1234567891011121314public class Test &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub MyObject object1 = new MyObject(); MyObject object2 = new MyObject(); object1.object = object2; object2.object = object1; object1 = null; object2 = null; System.gc(); &#125; finalize()即使某个对象是不可达的，也并不一定非死不可。宣告一个对象死亡，要经过两次标记过程：第一个是GC Roots不可达，第二步是此对象是否有必要执行finalize()方法。 如果该对象重写了finalize()方法且finalize()方法还没有被虚拟机所调用，则其对象需要执行该方法。 那么，该对象会放入一个队列之中，并由一个Finalizer线程去执行finalize()方法。finalize方法是对象拯救自己的最后一次方法，只需要与任何一个GC Roots建立关联即可。这样他就还是存活的。 12345678910111213141516171819202122232425262728293031323334353637383940public class FinalizeEscape &#123; public static FinalizeEscape SAVE=null; @Override protected void finalize() throws Throwable &#123; // TODO Auto-generated method stub super.finalize(); System.out.println("finalize excute...."); FinalizeEscape.SAVE=this; &#125; public void isAlive() &#123; System.out.println(" i am still alive ....."); &#125; public static void main(String[] args) throws Exception&#123; // TODO Auto-generated method stub SAVE=new FinalizeEscape(); SAVE=null; System.gc(); Thread.sleep(500); if(SAVE==null) &#123; System.out.println(" i am dead ....."); &#125;else &#123; SAVE.isAlive(); &#125; SAVE=null; System.gc(); Thread.sleep(500); if(SAVE==null) &#123; System.out.println(" i am dead ....."); &#125;else &#123; SAVE.isAlive(); &#125; &#125; /* 输出： finalize excute.... i am still alive ..... i am dead ..... */ 由此可见，SAVE对象的finalize()方法确实执行了，并在收集前成功逃脱了。 代码中有两段完全一样的方法，第一次成功逃脱，第二次因为已经执行过了finalize()方法，所以也就不在执行了，因此第二段代码逃脱失败。 然而，并不鼓励使用finalize()方法。 四种引用类型 强引用： 强引用是使用最普遍的引用。Object obj =new Object(); 如果一个对象具有强引用，那垃圾回收器绝不会回收它。当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。 软引用： 如果一个对象只具有软引用，则内存空间足够，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。使用SoftReferrnce类实现软引用。 弱引用： 被弱引用引用的对象只能生存到下一次垃圾回收之前。当GC开始工作时，无论内存是否充足，都会回收弱引用引用的对象。使用WeakReference来实现弱引用类。 虚引用： 顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。虚引用主要用来跟踪对象被垃圾回收器回收的活动。 方法区GC方法区主要回收废弃常量以及无用的类。 废弃常量，没有地方引用他。 废弃类需要满足以下条件： 该类所有实例已经被回收。 加载该类classLoader已经被回收。 该类的class对象没有在任何地方被引用。 对于jdk8之后方法区变为了元空间，如果Metaspace的空间占用达到了设定的最大值，也会触发GC来收集死亡对象和类的加载器。 MetaSpace GC GC算法标记-清除 标记出所有需要回收的对象，然后将做了标记的都给清除。缺点是导致内存碎片化。 复制 将内存一般分为A区域，一半分为B区域。图中我们将前两行分为A，后两行分为B。刚开始的时候，我们只使用A区域的内存，而不使用B区域的内存。 第一次GC，经过一次可达性分析后，我们将A中存活对象直接复制到B区域，然后直接将整块A区域清除。A区域变成未使用的。第二次GC，同理，将B的存活对象复制到A，将B清除，B变为空。 这样A和B区域交互使用。 这个算法可以解决内存碎片化的问题，但是会导致内存浪费，一次只能使用一半的内存。 新生代主要使用的是复制算法。一般来说，Eden：Survior1：Survior2=8：1：1，因为每次GC新生代垃圾都会有75%-90%，这样，直接将Eden幸存的对象复制到Survior1区域中，然后将Eden区域清除，第二次清除时，将Eden区域和S1区域幸村对象复制到S2区域，将Eden和S1区域清除，就这样，S1，S2两个区域交替使用，新生代内存利用空间可以达到90%，而且解决了内存碎片化的问题。注意，当Survior内存区域不够时（多于10%对象存活），可以向老年代进行分配担保。 适用于存活率比较低的对象，要是存活率过高的话，会造成大量复制，效率变低。 标记-整理复制算法在对象存活率较高时就会产生一个问题，因为要进行过多的复制操作，效率会降低，而且浪费空间会比较多。对于老年代，存活对象率比较高，而且对象比较大，占用内存大，所以不宜使用复制算法，采用标记整理算法。 将存活的对象移到回收对象留下的空间里，以形成连续的内存。 适用于存活率较高的。 总结新生代中，每次GC都有大量对象死去，少量存活，选用复制算法。 老年代中，对象存活率高，没有额外空间进行内存担保，使用标记-整理。 HotSpot算法实现两个问题 寻找GC Roots效率问题，如果逐个检查引用，太慢。 使用OopMap来解决，这个数据结构存储了引用以及他的作用范围(从哪个指令开始到哪个指令结束)。 在类加载完成的时候，就生成了一个OopMap。 一致性问题。寻找GC Roots这个阶段需要保证引用情况不再发生变化，因此需要发生GC停顿。 OopMap与Rememebered SetOopMap编译时就有了。 用于枚举GC Roots。 当垃圾回收时，收集线程会对栈上的内存进行扫描，看看那些位置上存储了Reference类型。如果发现了某个位置上存储的是Reference类型，就意味着这个引用所指向的对象在这一次垃圾回收过程中不能够回收。 但是要是逐个检查引用，这一样效率太低了。 于是采用空间换时间的方法，把栈中是引用类型的变量的位置记录下来，这样他指向的对象肯定是GC Roots。这样，再做GC的时候，就可以直接读取，不用全部扫描了。 一个线程意味着一个栈，一个栈由多个栈帧组成，一个栈帧对应着一个方法，一个方法里面可能有多个安全点。 gc 发生时，程序首先运行到最近的一个安全点停下来，然后更新自己的 OopMap ，记下栈上哪些位置代表着引用。枚举根节点时，递归遍历每个栈帧的 OopMap ，通过栈中记录的被引用对象的内存地址，即可找到这些对象（ GC Roots ）。 因为一个方法有多个安全点，每个安全点就有一个OopMap，所以，一个方法里有多个OopMap。 可以把oopMap简单理解成是调试信息。在源代码里面每个变量都是有类型的，但是编译之后的代码就只有变量在栈上的位置了。oopMap就是一个附加的信息，告诉你栈上哪个位置本来是个什么东西。 这个信息是在JIT编译时跟机器码一起产生的。因为只有编译器知道源代码跟产生的代码的对应关系。 每个方法可能会有好几个oopMap，就是根据safepoint把一个方法的代码分成几段，每一段代码一个oopMap，作用域自然也仅限于这一段代码。 循环中引用多个对象，肯定会有多个变量，编译后占据栈上的多个位置。那这段代码的oopMap就会包含多条记录。 Rememebered SetRememberedSet 用于处理这类问题：比如说，新生代 gc （它发生得非常频繁）。一般来说， gc 过程是这样的：首先枚举根节点。根节点有可能在新生代中，也有可能在老年代中。这里由于我们只想收集新生代（换句话说，不想收集老年代），所以没有必要对位于老年代的 GC Roots 做全面的可达性分析。但问题是，确实可能存在位于老年代的某个 GC Root，它引用了新生代的某个对象，这个对象你是不能清除的。那怎么办呢？ 维护一个表，记录别的代对新生代的引用关系，这个表叫Remembered Set。 在G1收集器中，堆被分成一个个region，难免会存在别的region中的对象会引用某个region的对象，那么，就对每一个region维护一个Remembered Set，记录其他所有region对象对他其中对象的引用。 安全点在OopMap的帮助下，可以很容易的寻找GC Roots，但是，每一个指令都可能导致OopMap的变化，如果为每一条指令都生成一个对应的OopMap，那么，将会需要大量的空间。于是，HotSpot只是在特定的点记录了这些信息，这些点叫做安全点，程序旨在安全点才停下来执行GC。 如何让让所有的线程跑到安全点中断呢？ 抢先式中断和主动式中断。 抢先式中断是把所有的线程都中断，然后把不在安全点上的线程恢复，直到他到达安全点上。 主动式中断：设置一个中断标志，各个线程主动区轮询这个标志，发现中断标志为真时，自己主动挂起。 垃圾收集器所有的收集器都避免不了stop the word，只可能尽可能的缩短。 以上是 HotSpot 虚拟机中的 7 个垃圾收集器，连线表示垃圾收集器可以配合使用。 单线程与多线程：单线程指的是垃圾收集器只使用一个线程，而多线程使用多个线程； 串行与并行：串行指的是垃圾收集器与用户程序交替执行，这意味着在执行垃圾收集的时候需要停顿用户程序；并行指的是垃圾收集器和用户程序同时执行。除了 CMS 和 G1 之外，其它垃圾收集器都是以串行的方式执行。 Serial 适用于新生代和老年代。 单线程收集器，在他进行垃圾收集时，必须暂停所有其他工作的线程。 新生代采用复制算法，老年代采用标记-整理算法。 ParNew Serial的多线程版本。除了Serial，只有ParNew可以与CMS一起使用。 适用于新生代和老年代。 新生代采用复制算法，老年代采用标记-整理算法。 Parallel Scavenge+Parallel oldParallel Scavenge一个新生代收集器，特点是吞吐量优先。经常与Parallel Old一起使用 。 在注重吞吐量的情况下，使用Parallel Scavenge+Parallel old（科学计算，天文计算等）。 Parallel Scavenge新生代采用复制算法，Parallel old老年代采用标记-整理。 CMS基于标记-清除算法。并不是标记整理。 注重于获取最短停顿时间。并发收集，分区处理。停顿时间短，在垃圾收集的时候，JVM还可以运行。 分为以下四个流程： 初始标记：仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿。 并发标记：进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿。 重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿。 并发清除：不需要停顿。 在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿。 CMS具有以下缺点： 在并发标记以及并发清除阶段，GC会占用一部分的CPU资源，会造成吞吐量下降CMS 默认启动的回收线程数=(CPU 数目+3)4 当 CPU 数&gt;4 时, GC线程一般占用不超过 25%的 CPU 资源, 但是当 CPU 数&lt;=4 时, GC线程 可能就会过多的占用用户 CPU 资源, 从而导致应用程序变慢, 总吞吐量降低.。 无法处理浮动垃圾，可能出现 Concurrent Mode Failure。浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾，这部分垃圾只能到下一次 GC 时才能进行回收。由于浮动垃圾的存在，因此需要预留出一部分内存，意味着 CMS 收集不能像其它收集器那样等待老年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。 标记 - 清除算法导致的空间碎片，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC。 G1用来替代CMS的。 特点 采用的是标记-整理算法+复制算法，避免产生内存空间碎片。标记整理出需要回收的region，region间使用复制算法。因此，从整体上看，G1是基于标记-整理的，从局部上来看(两个region之间)，是复制算法。 一般的垃圾收集器将内存分为Eden，Survior以及Old三类，且各个代都是连续的。而G1将整个Java堆分成一个个相等的独立区域，虽然还有分代的概念，但各个代不再是连续的，新生代和老年代不再物理隔离。内存的粒度变得更小了。 可预测的停顿。G1每次回收不是收集整代内存，而是根据优先列表收集几块内存(region)，到底要回收多少需要看用户的垃圾收集时间配置，配置的时间长，收集的就多。 如果应用的内存非常吃紧，对内存进行部分回收根本不够，始终要进行整个Heap的回收，那么G1要做的工作量就一点也不会比其它垃圾回收器少，而且因为本身算法复杂了一点，可能比其它回收器还要差。因此G1比较适合内存稍大一点的应用(一般来说至少4G以上)。 通过引入 Region 的概念，从而将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。这种划分方法带来了很大的灵活性，使得可预测的停顿时间模型成为可能。通过记录每个 Region 垃圾回收时间以及回收所获得的空间（这两个值是通过过去回收的经验获得），并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。 每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描。 适用场景 服务端多核CPU、JVM内存占用较大的应用。 运行过程中会产生大量内存碎片。 想要可控的，可预期的GC停顿时间。 收集过程 初始标记，标记GC Roots直接关联对象，需要暂停，时间短 并发标记，对GC Roots进行可达性分析，并发执行，时间比较长。 最终标记，修正并发标记阶段而产生的变动，这一段是暂停的。 筛选回收，将各个region根据回收价值和回收成本进行排序，然后进行收集。这个阶段需要暂停用户线程。 Minor GC and Full GCMinor GC回收新生代，因为新生代对象存活时间很短，因此Minor GC会频繁进行，执行速度也比较快。当Eden区域满了的话，会触发Minor GC。 Full GC回收新生代和老年代，老年代因为存活时间比较长，因此Full GC很少执行，速度也比较慢。 触发Full GC： 老年代空间不足。 空间分配担保失败。 新生代采用复制收集算法，需要将存活的对象复制到survivor中，然后直接清理Eden区，但是会有一种情况，就是存活的对象大于survivor内存空间，这样，就需要老年代分配担保，将survivor中无法分配的对象放入老年代。但是，万一老年代也不够用呢？ 加入老年代剩余最大连续可用空间大于Eden区，那么肯定可以直接放。 否则的话，看老年代是否允许担保失败，可以的话，检查老年代剩余最大连续可用空间是否大于历次晋升到老年代对象的平均大小，如果大于，尝试进行Minor GC，小于的话，直接Full GC。 CMS垃圾收集器浮动垃圾的问题。因为在CMS并发清理阶段用户线程也在运行，所以需要留出一定的空间做缓冲。这样，老年代没有满的时候就需要触发Full GC,默认是92%。但要是预留的空间无法满足程序需要，就会报 Concurrent Mode Failure 错误，并触发 Full GC。 对象分配策略 对象优先在Eden区分配。当Eden区没有足够的空间进行分配时，会触发Minor GC。如果启动了TLAB，那么优先在TLAB上分配，G1默认就是启动TLAB的。 大对象直接进入老年代。 长期存活对象将进入老年代，对象每熬过一次Minor GC，年龄增加一岁，当年龄达到阈值(默认是15),那么这个对象晋升到老年代。 动态对象年龄判定。虚拟机并不是永远地要求对象的年龄必须达到 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 中相同年龄所有对象大小的总和大于 Survivor 空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄。 参考OopMap详解 OopMap与Remembered Set G1垃圾收集器]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM类加载机制]]></title>
    <url>%2F2019%2F09%2F20%2FJVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Java程序运行时，有两个阶段，编译和运行。编译阶段将Java文件编译成class字节码文件，然后在运行阶段将class文件加载到内存，并对class文件解释执行。 Java跨平台原因Java语言跨平台的主要原因就是JVM以及字节码文件。 C语言是将高级语言直接解释成机器码，通过CPU指令集执行机器码，但是，不同架构的CPU，他的指令集可能是不一样的，这样就造成C语言难以跨平台。可是Java就不一样了，Java在机器和程序之间加了一次抽象的虚拟机。直接将Java程序编译成字节码，由Java虚拟机来解释字节码文件，对于不同的平台，解释器是不同的。Java源程序经过编译器编译后变成字节码，字节码由虚拟机解释执行，虚拟机将每一条要执行的字节码送给解释器，解释器将其翻译成特定机器上的机器码，然后在特定的机器上运行。 编译阶段 将Java文件转换成字节码文件。字节码文件存储了所有信息。 class文件中有一个class常量池，里面存放了字符串。 所以，类似于String s = “a”+”b”;在编译阶段会直接被优化为”ab”。 类加载阶段类加载就是将class文件加载到内存，并对数据进行校验，转换解析和初始化，最终转化成可被虚拟机使用的Java类型。类加载阶段是在运行期间完成的。 类加载阶段主要包括五个阶段：加载，验证，准备，解析，初始化。。 加载 通过一个类的全限定名获取字节码文件。 将字节码文件静态存储结构转化为运行时内存区域。 生成这个类的java.lang.class对象。存在于方法区（元空间）。 验证确保字节码文件信息是否合法。 准备为类变量(static 修饰)分配内存并设置初始值的阶段。 注意，这个阶段只是类变量设置初始值，而不包括实例变量。 设置初始值通常情况下指的是数据类型的零值。 1public static int a = 23; 这里只会将a设置为0，将a设置为23需要等到初始化阶段。 解析将class常量池内的符号引用替换为直接引用的过程。 初始化执行clinit()方法的过程，初始化类变量以及执行静态语句块。 clinit是类初始化的方法，init是对象初始化的方法，static静态语句块在clinit阶段执行，所以静态语句块肯定是先于构造函数执行的。 类初始化时机这几个阶段类必须要初始化，而不是类加载。 遇到new实例化对象，读取或者设置static字段。 反射调用。 初始化一个类，若父类还没有初始化，需要先初始化父类。 初始化主类(执行main方法的)。 类加载器对于任何一个类，都需要由加载他的类加载器以及这个类本身来确立他在JVM中的唯一性。比较两个类是否相等，首先应该是建立在同一个类加载器上的。两个类即使来自于同一个class文件，由不同的类加载器加载，这两个加载的类也是不相等的。 双亲委派模型 双亲委派机制，其工作原理的是，如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器，如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务(搜索范围内没有这个类)，子加载器才会尝试自己去加载，这就是双亲委派模式。 避免了类加载的混乱。比如说，在classpath下定义了一个java.lang.Object，要是没有双亲委派模型，那么应用程序类加载器会加载这个类，那么就会与启动类加载器加载的Object类冲突。但是要是有类加载机制，那么将会交给启动类加载器，这样加载的还是java自带的Object类，就不会产生冲突。 破坏双亲委派模型如何破坏双亲委派模型？ 继承ClassLoader，自己重写loadClass方法，然后加入自己逻辑，特定某些class可以按照你的方式处理。。 重写loadClass： findLoadedClass 委托parent加载器加载（这里注意bootstrap加载器的parent为null) 自行加载 打破委派机制要做的就是打乱2和3的顺序，通过类名筛选自己要加载的类，其他的委托给parent加载器 JDBC破坏因为类加载器受到加载范围的限制，在某些情况下父类加载器无法加载到需要的文件，这时候就需要委托子类加载器去加载class文件。 JDBC的Driver接口定义在JDK中，其实现由各个数据库的服务商来提供，比如MySQL驱动包。DriverManager 类中要加载各个实现了Driver接口的类，然后进行管理，但是DriverManager位于 $JAVA_HOME中jre/lib/rt.jar 包，由BootStrap类加载器加载，而其Driver接口的实现类是位于服务商提供的 Jar 包，根据类加载机制，当被装载的类引用了另外一个类的时候，虚拟机就会使用装载第一个类的类装载器装载被引用的类。也就是说BootStrap类加载器还要去加载jar包中的Driver接口的实现类。我们知道，BootStrap类加载器默认只负责加载 $JAVA_HOME中jre/lib/rt.jar 里所有的class，所以需要由子类加载器去加载Driver实现，这就破坏了双亲委派模型。通过线程上下文类加载器，默认是应用程序类加载器，可以通过Thread的方法进行设置。 Tomcat破坏tomcat破坏双亲委派模型 OSGI类加载器不再是双亲委派模型的树状结构，而是网状结构。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java内存管理]]></title>
    <url>%2F2019%2F09%2F20%2FJava%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[运行时数据区域包括程序计数器，java虚拟机栈，本地方法栈，方法区和堆。其中，java虚拟机栈，本地方法栈，程序计数器是每个线程私有的。 字节码文件经过类加载子系统从静态存储结构转化为方法区的运行时内存结构。运行时数据区域包括程序计数器，java虚拟机栈，本地方法栈，方法区和堆。其中，java虚拟机栈，本地方法栈，程序计数器是每个线程私有的，方法区以及堆是所有线程共享的。 堆所有线程共享。 主要存放对象以及数组对象的。 但是，由于现在逃逸技术的存在，对象并不一定都是存在于堆，还有可能存放在栈上。 java堆分为新生代和老年代，新生代又分为Eden区以及Survivor区。 当内存不足时，会产生OOM异常。 Java虚拟机栈线程私有，每一个线程都有一个自己的栈。 线程每执行一个方法，都会创建一个栈帧，用于存储局部变量表（对象引用，基本数据类型）等。方法调用直至完成的过程中，就是一个栈帧入栈和出栈的过程。两种异常情况： 当线程请求的栈深度超过最大值，会抛出 StackOverflowError 异常； 栈进行动态扩展时如果无法申请到足够内存，会抛出 OutOfMemoryError 异常。可以通过 -Xss 这个虚拟机参数来指定每个线程的 Java 虚拟机栈内存大小： 1java -Xss512M HackTheJava 本地方法栈与Java虚拟机栈类似，只不过一个是为Java方法服务，一个是为Native方法服务，其他都一样。Native方法就是Java调用非Java代码的接口。例如调用C语言实现的接口。 程序计数器可以看作是当前线程执行到的字节码的行号指示器。对于Java的多线程，为了使程序每次切换后能够恢复到正确的执行位置，因此每一个线程必须要有自己独立的程序计数器。如果线程执行的是Java方法，记录的是正在执行的虚拟机字节码指令的地址（如果正在执行的是本地方法则为空）。 方法区各个线程共享的区域。存放的是虚拟机加载的类信息，常量，静态变量。 在HotSpot中，永久代是方法区的实现。因为GC分代收集拓展到方法区。方法区主要是废弃类和常量的收集，对于方法区，也可以选择不进行垃圾回收。 一般来说，方法区不进行垃圾收集。 在jdk1.8之后，HotSpot中，删去了永久代，永久代的相关信息存放在了元空间。 元空间与永久代最大的不同就是，元空间并不在JVM中，而是在本地内存。主要原因还是因为永久代的大小难以确定，容易发生OOM，而移到元空间，只会受到本地内存大小的限制。 运行时常量池运行时常量池是方法区的一部分。 class常量池：我们写的每一个Java类被编译后，就会形成一份class文件；class文件中除了包含类的版本、字段、方法、接口等描述信息外，还有一项信息就是常量池(constant pool table)，用于存放编译器生成的各种字面量(Literal)和符号引用(Symbolic References)。 class常量池在类加载完成后就会放入运行时常量池存放。 字符串常量池：存放字符串，位于堆内。常量池中同时存在字符串常量和字符串引用。直接赋值和用字符串调用String构造函数都可能导致常量池中生成字符串常量;而intern()方法会尝试将堆中对象的引用放入常量池。 类加载子系统类加载子系统负责从文件系统或者网络中加载 Class 信息，加载的类信息存放于一块称 为方法区的内存空间。 局部变量表所需要的内存空间在编译阶段就分配完毕。 对象的创建过程 虚拟机遇到一个new指令，首先从常量池中获取这个类的符号引用，检查这个符号引用代表的类是否被加载。 要是没有被加载，必须执行相应的类加载的过程。 为对象分配内存，主要有指针碰撞和空闲列表两种办法。指针碰撞是所有使用过的内存放一边，未使用过的内存放一边，中间一个指针作为分界线，当为一个对象分配内存的时候，直接移动指针即可。空闲列表适用于空闲内存和使用过的内存互相交错，内存的使用情况都存在一个表上，根据这个表再去分配内存。指针碰撞适用于标记-整理算法，空闲列表适用于标记-清除算法。 但是，如何解决分配内存过程中的并发问题呢？ 一个就是同步加锁。 另一个就是TLAB的使用，预先给每个线程在Java堆中都分配了一小块内存，哪个线程要给对象分配内存，直接在自己的TLAB中分配，当TLAB用完了，再分配新的，这一步才需要加锁。 设置对象头 执行init方法，初始化成员变量。 对象的内存布局对象在内存中主要分为三个部分：对象头，实例数据以及对齐填充。 对象头主要结构是由Mark Word 和 Class Metadata Address 组成 。Class Metadata Address存储的是该对象属于类的地址，即可以判断这个对象属于哪一个类。 MarkWord有五种类型：]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面向对象概述]]></title>
    <url>%2F2019%2F09%2F19%2F%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[面向对象有三大特性： 封装。只对外提供接口由外界访问。 继承。 多态。多态的三个条件：继承，重写，以及向上转型（父类引用指向子类对象）。 访问权限修饰符private:除了自己没有其他任何类可以访问。protected:同一包下的，以及自己的自类可以访问。default：同一包下面的。public：任何类都可以访问。 重写与重载重写：override，重新实现父类的方法。发生在运行期，动态分派。重载：方法名称相同，参数不同。返回值类型不同，参数类型相同不算是重载。发生在编译器，静态分派。 抽象类和接口抽象类使用abstract关键字声明，且抽象类至少应该包含一个抽象方法(只有声明没有实现)。 抽象类不可以被实例化。 抽象方法不能是private，这样方法就不能继承了。抽象类不能是final的。 接口在JDK8之前，没有任何方法的实现。从JDK8之后，接口也可以有默认方法的实现。 接口的成员都只能是public的。 接口的字段是public static final的，因此，接口字段一旦定义就不可以改了。 但是，在JDK1.8之后，interface加了一些新的特性。 可以添加静态方法。 1234567public interface TestInterface &#123; public static String sayHello() &#123; return "Hello world!"; &#125;&#125; 可以为接口方法提供一个默认实现。使用default标记。 12345678interface MyInterface&#123; String myNewName(String newName); default String myOldName()&#123; return "chao"; &#125;&#125; 区别 类只可以继承一个抽象类，却可以实现多个接口。 接口字段是static final的，不可以再去修改的，而抽象类却没有这种要求。 接口成员是public的，抽象类却没有这种要求。 super关于构造方法当new一个子类的时候，一定会先调用父类的构造方法，然后再去调用子类的构造方法。 123456789101112131415161718public class Parent &#123; public Parent()&#123; System.out.println("parent"); &#125;&#125;public class Son extends Parent &#123; public Son()&#123; System.out.println("son"); &#125;&#125;Son son = new Son();/*输出：parent son也就是说。当构造一个子类的时候，一定会先调用父类的构造方法。默认是调用父类无参的构造函数，若是想调用其它构造函数，可以通过super关键字实现。*/ 既然创建子类对象的时候，一定会先调用父类的构造方法，那么是否创建了父类呢？ 答案是没有。 只是创建了一个子类对象，this完全引用这个子类对象，super引用子类可以继承的成员变量以及方法。 super作用 访问父类的构造函数：可以使用 super() 函数访问父类的构造函数，从而委托父类完成一些初始化的工作。应该注意到，子类一定会调用父类的构造函数来完成初始化工作，一般是调用父类的默认构造函数，如果子类需要调用父类其它构造函数，那么就可以使用 super 函数。 访问父类的成员：如果子类重写了父类的某个方法，可以通过使用 super 关键字来引用父类的方法实现。 内部类在一个类中再定义一个类。 内部类的好处 内部类可以访问外部类的所有成员，包括private。 为什么内部类可以随意访问外部类的成员？ 持有引用。当外部类的对象创建了一个内部类的对象时，内部类对象必定会秘密捕获一个指向外部类对象的引用，然后访问外部类的成员时，就是用那个引用来选择外围类的成员的。当然这些编辑器已经帮我们处理了。 内部类可以对外隐藏。 可以实现多重继承。 12345678910111213141516171819202122232425262728293031323334353637383940//类一public class ClassA &#123; public String name()&#123; return "liutao"; &#125; public String doSomeThing()&#123; // doSomeThing &#125;&#125;//类二public class ClassB &#123; public int age()&#123; return 25; &#125;&#125;//类三public class MainExample&#123; private class Test1 extends ClassA&#123; public String name()&#123; return super.name(); &#125; &#125; private class Test2 extends ClassB&#123; public int age()&#123; return super.age(); &#125; &#125; public String name()&#123; return new Test1().name(); &#125; public int age()&#123; return new Test2().age(); &#125; public static void main(String args[])&#123; MainExample mi=new MainExample(); System.out.println("姓名:"+mi.name()); System.out.println("年龄:"+mi.age()); &#125;&#125; 内部类与外部类的关系 对于非静态内部类，内部类的创建依赖外部类的实例对象，在没有外部类实例之前是无法创建内部类的。先有外部类对象，再有内部类对象。 对于静态内部类，内部类并不依赖于外部类对象的创建，static依赖于类本身，并不依赖类实例对象。 普通内部类不可以有静态成员，因为普通内部类需要依赖于外部对象而存在，需要outer.new InnerClass();，他是与对象相关的。 静态可以访问静态的，不可以访问非静态的；非静态静态和非静态都可以访问。所以，静态内部类不可以访问外部类非静态成员。 内部类创建12ClassOuter outer = new ClassOuter();ClassOuter.InnerClass inner = outer.new InnerClass(); 普通内部类123456public class InnerClassTest &#123; public class InnerClassA &#123; &#125;&#125; 内部类对象可以访问外部类对象中所有访问权限的字段，同时，外部类对象也可以通过内部类的对象引用来访问内部类中定义的所有访问权限的字段。 静态内部类静态内部类就像外部类的一个静态成员一样，创建其对象无需依赖外部类对象（访问一个类的静态成员也无需依赖这个类的对象，因为它是独立于所有类的对象的）。但是于此同时，静态内部类中也无法访问外部类的非静态成员，因为外部类的非静态成员是属于每一个外部类对象的，而本身静态内部类就是独立外部类对象存在的，所以静态内部类不能访问外部类的非静态成员，而外部类依然可以访问静态内部类对象的所有访问权限的成员，这一点和普通内部类无异。 匿名内部类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class InnerClassTest &#123; public int field1 = 1; protected int field2 = 2; int field3 = 3; private int field4 = 4; public InnerClassTest() &#123; System.out.println("创建 " + this.getClass().getSimpleName() + " 对象"); &#125; // 自定义接口 interface OnClickListener &#123; void onClick(Object obj); &#125; private void anonymousClassTest() &#123; // 在这个过程中会新建一个匿名内部类对象， // 这个匿名内部类实现了 OnClickListener 接口并重写 onClick 方法 OnClickListener clickListener = new OnClickListener() &#123; // 可以在内部类中定义属性，但是只能在当前内部类中使用， // 无法在外部类中使用，因为外部类无法获取当前匿名内部类的类名， // 也就无法创建匿名内部类的对象 int field = 1; @Override public void onClick(Object obj) &#123; System.out.println("对象 " + obj + " 被点击"); System.out.println("其外部类的 field1 字段的值为: " + field1); System.out.println("其外部类的 field2 字段的值为: " + field2); System.out.println("其外部类的 field3 字段的值为: " + field3); System.out.println("其外部类的 field4 字段的值为: " + field4); &#125; &#125;; // new Object() 过程会新建一个匿名内部类，继承于 Object 类， // 并重写了 toString() 方法 clickListener.onClick(new Object() &#123; @Override public String toString() &#123; return "obj1"; &#125; &#125;); &#125; public static void main(String[] args) &#123; InnerClassTest outObj = new InnerClassTest(); outObj.anonymousClassTest(); &#125;&#125; 匿名内部类中可以使用外部类的属性，但是外部类却不能使用匿名内部类中定义的属性，因为是匿名内部类，因此在外部类中无法获取这个类的类名，也就无法得到属性信息。 当匿名内部类访问局部变量的时候，局部变量必须是final的。 12345678910111213141516171819public class Button &#123; public void click(final int params)&#123; //匿名内部类，实现的是ActionListener接口 new ActionListener()&#123; public void onAction()&#123; System.out.println("click action..." + params); &#125; &#125;.onAction(); &#125; //匿名内部类必须继承或实现一个已有的接口 public interface ActionListener&#123; public void onAction(); &#125; public static void main(String[] args) &#123; Button button=new Button(); button.click(); &#125;&#125; 原因是：因为局部变量和匿名内部类的生命周期不同。 匿名内部类是创建后是存储在堆中的，而方法中的局部变量是存储在Java栈中，当方法执行完毕后，就进行退栈，同时局部变量也会消失。那么此时匿名内部类还有可能在堆中存储着，那么匿名内部类要到哪里去找这个局部变量呢？ 为了解决这个问题编译器为自动地帮我们在匿名内部类中创建了一个局部变量的备份，也就是说即使方法执结束，匿名内部类中还有一个备份，自然就不怕找不到了。 但是问题又来了。如果局部变量中的a不停的在变化。那么岂不是也要让备份的a变量无时无刻的变化。为了保持局部变量与匿名内部类中备份域保持一致。编译器不得不规定死这些局部域必须是常量，一旦赋值不能再发生变化了。所以为什么匿名内部类应用外部方法的域必须是常量域的原因所在了。 特别注意：在Java8中已经去掉要对final的修饰限制，但其实只要在匿名内部类使用了，该变量还是会自动变为final类型（只能使用，不能赋值）。 内部类导致内存泄漏 如果一个匿名内部类没有被任何引用持有，那么匿名内部类对象用完就有机会被回收。 如果内部类仅仅只是在外部类中被引用，当外部类的不再被引用时，外部类和内部类就可以都被GC回收。 如果当内部类的引用被外部类以外的其他类引用时，就会造成内部类和外部类无法被GC回收的情况，即使外部类没有被引用，因为内部类持有指向外部类的引用）。 所以，内部类内存泄露的原因就是有外部类以外的其他引用，这样内部类和外部类都无法被回收。 可以通过使用静态内部类来解决。 分析内部类]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 基础]]></title>
    <url>%2F2019%2F09%2F18%2Fjava-%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[包装类型装箱12// 装箱 调用了 Integer.valueOf(2)，将int变成了一个Integer对象Integer x = 2; 装箱转换是指将一个值类型隐式地转换成一个object 类型，也就是创建一个object 实例并将这个值复制给这个object。 拆箱拆箱转换是指将一个对象类型显式地转换成一个值类型。 12Integer x = 2; //装箱int y = x; // 拆箱 调用了 X.intValue() 装箱和拆箱会造成相当大的性能损耗，因此尽量应该避免大量的装箱拆箱操作。 缓存池new Integer()与Integer.Valueof()区别： new Integer每次都会新建一个对象 Integer.Valueof()会复用缓存池中的对象 123456Integer x = new Integer(123);Integer y = new Integer(123);System.out.println(x == y); // falseInteger z = Integer.valueOf(123);Integer k = Integer.valueOf(123);System.out.println(z == k); // true 编译器会在自动装箱过程调用 valueOf() 方法，因此多个值相同且值在缓存池范围内的 Integer 实例使用自动装箱来创建，那么就会引用相同的对象。 123//a = bInteger a = 123;Integer b = 123; String基本类型的变量数据都是存在栈中的，String常量放在常量池里面，String对象放在堆里面。 String常量String常量存放在常量池里面，常量池中相同的值只有一个。 123String s1="hello";String s2="hello";System.out.println(s1==s2);//true 第一句代码执行后就在常量池中创建了一个值为hello的String对象； 第二句执行时，因为常量池中存在hello所以就不再创建新的String对象了。 此时该字符串的引用在虚拟机栈里面。 因为s1和s2指向的是同一个对象，所以s1==s2 String对象String对象的本质是一个不可变的char数组。 123String a = new String("skj");String b = new String("skj");System.out.println(a==b);//false new String(“skj”)这一步到底做了什么？ 在字符串常量池里面创建一个对象，就是”skj”,首先会检查常量池里面有没有这个对象”skj”，没有的话在创建并返回对象的引用，有的话就直接返回这个对象的引用。 在堆上创建一个对象， new String，String对象的本质就是一个char数组，所以String对象中的char数组指向之前返回对象的引用 所以，new String(“skj”)这一句实际上是创建了两个对象，一个在字符串常量池，一个在堆上。 String特性 Strings are constant; their values cannot be changed after they are created. String buffers support mutable strings. Because String objects are immutable they can be shared. String是不可变的，因为String的本质是一个final char[]，所以String同时又是线程安全的。 String由final修饰，是不可以继承的。 字符串拼接问题12String str0 = "a";String str1 = str0 + "b"; 编译成字节码： 123456789101112131415 public static void main(java.lang.String[]); Code: 0: ldc #2 // String a 2: astore_1 3: new #3 // class java/lang/StringBuilder 6: dup 7: invokespecial #4 // Method java/lang/StringBuilder."&lt;init&gt;":()V 10: aload_1 11: invokevirtual #5 // Method java/lang/StringBuilder.append(Ljava/lang/String;)Ljava/lang/StringBuilder; 14: ldc #6 // String b 16: invokevirtual #5 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 19: invokevirtual #7 // Method java/lang/StringBuilder.toString()Ljava/lang/String; 22: astore_2 23: return&#125; 转换成java就是： 12345String str0 = "a";StringBuilder sb = new StringBuilder();sb.append(str0).append("b");String str1 = sb.toString();return str1; 所以，字符串的拼接主要是通过StringBuilder来实现的。 要注意的是最后还有toString，返回的是一个String对象。 为什么返回的是一个新的String对象呢？ 因为String类的char数组是final的，他的指针一旦指向了常量池的某个String，就不可以再改变了. 1234String str0 = "a";for (int i = 0; i &lt; 10000; i++) &#123; str0 += "a";&#125; 当我们在循环体中进行字符串拼接，在循环体里面，每次拼接都会生成一个StringBuilder的临时对象，那么这个程序片段执行下去就会产生10000个StringBuilder的临时对象，这10000个临时对象都是必要的吗？显然不是，我们可以在循环体外直接创建一个StringBuilder对象，然后在循环体中通过append方法拼接字符串，这样就省下了创建并回收10000个临时对象的消耗。 因此，当我们大量使用字符串拼接的时候，还是使用StringBuilder比较好。 拼接示例 使用字符串连接符拼接 ： String s2=”se”+”cond”; 使用字符串加引用拼接 ： String s12=”first”+s2; 使用new String(“”)创建 ： String s3 = new String(“three”); 使用new String(“”)拼接 ： String s4 = new String(“fo”)+”ur”; 使用new String(“”)拼接 ： String s5 = new String(“fo”)+new String(“ur”); s2 ：这个在编译期间就自动进行了优化的，在常量池中存储一个”second”，并且s2指向它。 s12 ： JVM对于字符串引用，由于在字符串的”+”连接中，有字符串引用存在，而引用的值在程序编译期是无法确定的，即(&quot;first&quot;+s2)无法被编译器优化，只有在程序运行期来动态分配使用StringBuilder连接后的新String对象赋给s12。(编译器创建一个StringBuilder对象，并调用append()方法，最后调用toString()创建新String对象，以包含修改后的字符串内容)，常量池中并没有产生新的字符串常量。 s3 ： 用new String() 创建的字符串不是常量，不能在编译期就确定，所以new String() 创建的字符串不放入常量池中，它们有自己的地址空间。但是”three”字符串常量在编译期也会被加入到字符串常量池（如果不存在的话） s4 ： 同样不能在编译期确定，但是”fo”和”ur”这两个字符串常量也会添加到字符串常量池中，并且在堆中创建String对象。（字符串常量池并不会存放”four”这个字符串） s5 ： 原理同s4。 StringBuilderString的内部实现是一个用final的数组，因此String对象是不可变的，我们每次修改String时，实际上都是new出来了一个新的对象。因此，对于经常进行字符串的修改操作时，String类就需要不断创建新对象，性能极低。StringBuilder内部也是封装的一个字符数组，只不过该数组非final修饰，可以不断修改。所以对于一些经常需要修改字符串的情况，我们应首选StringBuilder。 123456789/** * The value is used for character storage. */ char[] value; /** * The count is the number of characters used. */ int count; append()1234567891011121314151617public AbstractStringBuilder append(String str) &#123; if (str == null) return appendNull(); int len = str.length(); ensureCapacityInternal(count + len); str.getChars(0, len, value, count); count += len; return this;&#125;private void ensureCapacityInternal(int minimumCapacity) &#123; // overflow-conscious code if (minimumCapacity - value.length &gt; 0) &#123; value = Arrays.copyOf(value, newCapacity(minimumCapacity)); &#125; &#125; 我们可以看到，当StringBuilder添加元素的时候，首先判断char[]是否满了，要是满了，Arrays.copyOf对数组进行扩容（返回的是一个新数组）。最后append的方法返回的this，也就是说，与String不同，他并没有创建一个新的对象，主要原因还是char[]不是final的，是可变的，他就可以转换新的指向。 StringBuilder，StringBuffer，String区别StringBuffer和StringBuilder都继承了抽象类AbstractStringBuilder，这个抽象类和String一样也定义了char[] value和int count，但是与String类不同的是，它们没有final修饰符。因此得出结论：String、StringBuffer和StringBuilder在本质上都是字符数组，不同的是，在进行连接操作时，String每次返回一个新的String实例，而StringBuffer和StringBuilder的append方法直接返回this，所以这就是为什么在进行大量字符串连接运算时，不推荐使用String，而推荐StringBuffer和StringBuilder。那么，哪种情况使用StringBuffe？哪种情况使用StringBuilder呢？ 12345678910public StringBuilder append(String str) &#123; super.append(str); return this; &#125;public synchronized StringBuffer append(String str) &#123; toStringCache = null; super.append(str); return this; &#125; 区别很明显，StringBuffer加了synchronized关键字，是线程安全的。 为何String要设计成不可变的？ 线程安全 字符串常量池的需要。字符串常量池的诞生是为了提升效率和减少内存分配。可以说我们编程有百分之八十的时间在处理字符串，而处理的字符串中有很大概率会出现重复的情况。正因为String的不可变性，常量池很容易被管理和优化。 字符串不变，HashCode也不变，便于缓存Hash Code，不需要重复计算HashCode。 intern()字符串常量池是在编译期间产生的，通过String的intern()也可以在运行时向字符串常量池放入字符串。 When the intern method is invoked, if the pool already contains a string equal to this String object as determined by the equals(Object) method, then the string from the pool is returned. Otherwise, this String object is added to the pool and a reference to this String object is returned. 简单来说就是intern用来返回常量池中的某字符串，如果常量池中已经存在该字符串，则直接返回常量池中该对象的引用。否则，在常量池中加入该对象，然后 返回引用。 123456789101112131415public static void main(String[] args) &#123; String s = new String("1"); s.intern(); String s2 = "1"; System.out.println(s == s2); String s3 = new String("1") + new String("1"); s3.intern(); String s4 = "11"; System.out.println(s3 == s4);&#125;/**输出：false true**/ 分析一下： 先看s3和s4.String s3 = new String(&quot;1&quot;) + new String(&quot;1&quot;);，这样，在字符串常量池创建了一个”1”，并且在堆里也创建了一个对象”11”，但在11中是没有对象的。s3.intern()，先去常量池看看有没有”11”，没有，需要在常量池中存储一份”11”，但是在jdk8中常量池已经转移到堆中了，所以可以直接存储堆中的引用(在jdk6之前，常量池还在perm区，就需要再在常量池中存储一份)。所以，s4实际上是指向堆上对象的引用。 再看s1和s2.String s = new String(&quot;1&quot;);在常量池内已经存储了1，所以s3.intern()啥也没做，s还是指向堆上的对象，s1指向的是常量池的对象。 所以，String#intern 方法时，如果存在堆中的对象，会直接保存对象的引用，而不会重新创建对象。 String#intern的使用 位运算符&amp;:按位与 |:按位或 ~:异或 ^:取反 &lt;&lt;:左移位运算，同理还有右移位运算。 关键字final数据：声明数据为常量，一旦初始化之后及不可以改变。 方法：声明方法不可以被重写。 类：声明类不可以被继承。 static静态变量：类变量，这个变量是属于这个类的，类的所有实例共享，在内存中只存在一份。 静态方法：他在类加载的时候就存在了，它不依赖于任何实例，所以static方法必须实现。 static代码块：在类初始化的时候执行一次。 静态成员不可以访问非静态成员，非静态成员可以访问静态成员和非静态成员。 Object方法equals() and hashCode()hashcode()返回的是散列值，equals()用来判断两个对象是否等价，所以在重写equals()方法时一定要先重写hashcode()。等价的对象散列值一定相同，但是散列值相同对象不一定等价。 clone()需要实现Clonable接口并重写clone()方法，才可以实现拷贝。 123456789public class CloneExample implements Cloneable &#123; private int a; private int b; @Override public Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125;&#125; 浅拷贝拷贝这个对象的时候，只对基本数据类型进行拷贝，而引用数据类型只是进行了引用的传递，这两个对象还是共享的引用数据类型。 1234567891011121314151617181920212223242526272829303132333435public class ShallowCloneExample implements Cloneable &#123; private int[] arr; public ShallowCloneExample() &#123; arr = new int[10]; for (int i = 0; i &lt; arr.length; i++) &#123; arr[i] = i; &#125; &#125; public void set(int index, int value) &#123; arr[index] = value; &#125; public int get(int index) &#123; return arr[index]; &#125; @Override protected ShallowCloneExample clone() throws CloneNotSupportedException &#123; return (ShallowCloneExample) super.clone(); &#125;&#125;ShallowCloneExample e1 = new ShallowCloneExample();ShallowCloneExample e2 = null;try &#123; e2 = e1.clone();&#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace();&#125;e1.set(2, 222);System.out.println(e2.get(2)); // 222,e1修改了，e2也变了，说明两人引用的是同一个对象 深拷贝在对引用数据类型拷贝的时候，创建了一个新的对象。 123456789101112131415161718192021222324252627282930313233343536373839public class DeepCloneExample implements Cloneable &#123; private int[] arr; public DeepCloneExample() &#123; arr = new int[10]; for (int i = 0; i &lt; arr.length; i++) &#123; arr[i] = i; &#125; &#125; public void set(int index, int value) &#123; arr[index] = value; &#125; public int get(int index) &#123; return arr[index]; &#125; @Override protected DeepCloneExample clone() throws CloneNotSupportedException &#123; DeepCloneExample result = (DeepCloneExample) super.clone(); result.arr = new int[arr.length]; for (int i = 0; i &lt; arr.length; i++) &#123; result.arr[i] = arr[i]; &#125; return result; &#125;&#125;DeepCloneExample e1 = new DeepCloneExample();DeepCloneExample e2 = null;try &#123; e2 = e1.clone();&#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace();&#125;e1.set(2, 222);System.out.println(e2.get(2)); // 2 但是，一般来说，不推荐使用clone，可以使用拷贝构造函数来做。 12345678910111213141516171819202122232425262728293031public class CloneConstructorExample &#123; private int[] arr; public CloneConstructorExample() &#123; arr = new int[10]; for (int i = 0; i &lt; arr.length; i++) &#123; arr[i] = i; &#125; &#125; public CloneConstructorExample(CloneConstructorExample original) &#123; arr = new int[original.arr.length]; for (int i = 0; i &lt; original.arr.length; i++) &#123; arr[i] = original.arr[i]; &#125; &#125; public void set(int index, int value) &#123; arr[index] = value; &#125; public int get(int index) &#123; return arr[index]; &#125;&#125;CloneConstructorExample e1 = new CloneConstructorExample();CloneConstructorExample e2 = new CloneConstructorExample(e1);e1.set(2, 222);System.out.println(e2.get(2)); // 2 反射反射的核心是 JVM 在运行时才动态加载类或调用方法/访问属性，它不需要事先（写代码的时候或编译期）知道运行对象是谁。 当我们的程序在运行时，需要动态的加载一些类这些类可能之前用不到所以不用加载到jvm，而是在运行时根据需要才加载，这样的好处对于服务器来说不言而喻。 举个例子我们的项目底层有时是用mysql，有时用oracle，需要动态地根据实际情况加载驱动类，这个时候反射就有用了，假设 com.java.dbtest.myqlConnection，com.java.dbtest.oracleConnection这两个类我们要用，这时候我们的程序就写得比较动态化，通过Class tc = Class.forName(“com.java.dbtest.TestConnection”);通过类的全类名让jvm在服务器中找到并加载这个类，而如果是oracle则传入的参数就变成另一个了。 反射使用获取class对象1Class s = Class.forName("java.lang.String"); 创建实例1s.newInstance(); 获取方法123456//获取类或接口生命的方法，但不包括继承的方法public Method[] getDeclaredMethods() throws SecurityException//获取公有方法public Method[] getMethods() throws SecurityException//获取特定的方法，根据参数方法名以及参数类型public Method getMethod(String name, Class&lt;?&gt;... parameterTypes) 获取变量信息 getFiled：访问公有的成员变量 getDeclaredField：所有已声明的成员变量，但不能得到其父类的成员变量 调用方法通过invoke 123456789101112public class test1 &#123; public static void main(String[] args) throws IllegalAccessException, InstantiationException, NoSuchMethodException, InvocationTargetException &#123; Class&lt;?&gt; klass = methodClass.class; //创建methodClass的实例 Object obj = klass.newInstance(); //获取methodClass类的add方法 Method method = klass.getMethod("add",int.class,int.class); //调用method对应的方法 =&gt; add(1,4) Object result = method.invoke(obj,1,4); System.out.println(result); &#125;&#125; 访问私有方法和私有变量甚至可以通过反射访问私有成员。 只需要setAccessible(true)即可。 123456789101112131415161718192021222324private static void modifyPrivateFiled() throws Exception &#123; //1. 获取 Class 类实例 TestClass testClass = new TestClass(); Class mClass = testClass.getClass(); //2. 获取私有变量 Field privateField = mClass.getDeclaredField("MSG"); //3. 操作私有变量 if (privateField != null) &#123; //获取私有变量的访问权 privateField.setAccessible(true); //修改私有变量，并输出以测试 System.out.println("Before Modify：MSG = " + testClass.getMsg()); //调用 set(object , value) 修改变量的值 //privateField 是获取到的私有变量 //testClass 要操作的对象 //"Modified" 为要修改成的值 privateField.set(testClass, "Modified"); System.out.println("After Modify：MSG = " + testClass.getMsg()); &#125;&#125; 反射机制 深入解析Java反射 异常Exception可以通过try catch处理并且使程序恢复。 Error是程序运行时错误，程序会崩溃并且无法恢复。 泛型泛型就是参数化类型，在泛型使用过程中，操作类型的数据类型被定义为一个参数。 泛型最常见的使用是在容器中，我们给容器添加泛型，这样我们可以把所需要的类型作为参数传递给容器，这样，容器就可以接受所有类型的数据，而且同时只能是一个数据，保证了程序的健壮性。 泛型主要有泛型类，泛型接口，泛型方法。 在编译之后程序会采取去泛型化的措施。也就是说Java中的泛型，只在编译阶段有效。在编译过程中，正确检验泛型结果后，会将泛型的相关信息擦出，并且在对象进入和离开方法的边界处添加类型检查和类型转换的方法。也就是说，泛型信息不会进入到运行时阶段。 泛型类1234567891011121314//此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型//在实例化泛型类时，必须指定T的具体类型public class Generic&lt;T&gt;&#123; //key这个成员变量的类型为T,T的类型由外部指定 private T key; public Generic(T key) &#123; //泛型构造方法形参key的类型也为T，T的类型由外部指定 this.key = key; &#125; public T getKey()&#123; //泛型方法getKey的返回值类型为T，T的类型由外部指定 return key; &#125;&#125; 泛型接口123public interface Generator&lt;T&gt; &#123; public T next();&#125; 泛型方法12345678910111213141516171819class DataHolder&lt;T&gt;&#123; T item; public void setData(T t) &#123; this.item=t; &#125; public T getData() &#123; return this.item; &#125; /** * 泛型方法 * @param e */ public &lt;E&gt; void PrinterInfo(E e) &#123; System.out.println(e); &#125;&#125; public 与返回值中间的E声明这是一个泛型方法，只有声明了才可以使用泛型 没有声明，只是传参的时候使用了泛型，并不是一个泛型方法。 与泛型类的定义一样，此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型。 123456789101112131415161718192021222324252627/** * 这是一个泛型类 */class GenericClassDemo&lt;T&gt; &#123; /** * 这个不是泛型方法，只是使用了泛型类中已声明的T */ public void show1(T t)&#123; System.out.println(t.toString()); &#125; /** * 泛型方法，使用泛型E，这种泛型E可以为任意类型。可以类型与T相同，也可以不同。 * 由于下面的泛型方法在声明的时候声明了泛型&lt;E&gt;，因此即使在泛型类中并未声明泛型， * 编译器也能够正确识别泛型方法中识别的泛型。 */ public &lt;E&gt; void show2(E e)&#123; System.out.println(e.toString()); &#125; /** * 在泛型类中声明了一个泛型方法，使用泛型T，注意这个T是一种全新的类型; * 可以与泛型类中声明的T不是同一种类型。 * show3和show2的E和T只是简单的代指泛型,与泛型类中的T并不是一个 */ public &lt;T&gt; void show3(T t)&#123; System.out.println(t.toString()); &#125;&#125; 泛型擦除1234567891011List&lt;String&gt; stringArrayList = new ArrayList&lt;String&gt;();List&lt;Integer&gt; integerArrayList = new ArrayList&lt;Integer&gt;();Class classStringArrayList = stringArrayList.getClass();Class classIntegerArrayList = integerArrayList.getClass();if(classStringArrayList.equals(classIntegerArrayList))&#123; System.out.println("----equals----");&#125;//输出：----equals---- 通过上面的例子可以证明，在编译之后程序会采取去泛型化的措施。也就是说Java中的泛型，只在编译阶段有效。在编译过程中，正确检验泛型结果后，会将泛型的相关信息擦出，并且在对象进入和离开方法的边界处添加类型检查和类型转换的方法。也就是说，泛型信息不会进入到运行时阶段 通配符上界通配符&lt;? extends T&gt;,只能放置T以及T的子类。下界通配符&lt;? superT&gt;,只能防止T以及T的父类。无界通配符&lt;?&gt; ,没有要求。深入理解泛型 泛型详解]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DirectIO和PageCache]]></title>
    <url>%2F2019%2F09%2F11%2FDirectIO%E5%92%8CPageCache%2F</url>
    <content type="text"><![CDATA[PageCachePageCache一页有4KB左右。 当需要写入磁盘的时候，若每写入一个字节数据就调用IO，这样效率就太低了，所以在操作系统的底层会有一个缓冲区，叫做PageCache，当PageCache中存满了，再写入磁盘，这样大大减少了磁盘IO的次数。 上图是写入磁盘的过程，我们使用MMap或者是FileChannel都会经过PageCache层。例如，我们使用FileChannel的时候，先写进DirectByteBuffer中，当buffer中数据满的时候，先写入PageCache，再写入磁盘。 同样的，读取数据也是一样的，将数据以及其邻近的一些数据读取到PageCache。 例如，当用户发起一个 fileChannel.read(4kb) 之后，实际发生了两件事 操作系统从磁盘加载了 16kb 进入 PageCache，这被称为预读 操作通从 PageCache 拷贝 4kb 进入用户内存 最终我们在用户内存访问到了 4kb，为什么顺序读快？很容量想到，当用户继续访问接下来的[4kb,16kb]的磁盘内容时，便是直接从 PageCache 去访问了。试想一下，当需要访问 16kb 的磁盘内容时，是发生4次磁盘 IO 快，还是发生1次磁盘 IO+4 次内存 IO 快呢？答案是显而易见的，这一切都是 PageCache 带来的优化。 DirectIO虽然PageCache很好，但是我们有时候并不希望使用PageCache。 当我们有时候进行随即读的时候，其实有时候并不需要PageCache的预读。 PageCache是操作系统层面上的概念，用很难干预，User BufferCache显然比PageCache要可控的多。 当操作系统回收 PageCache 内存的速度低于应用写缓存的速度时，会影响磁盘写入的速率，直接表现为写入 RT 增大，这被称之为“毛刺现象”。 而DirectIO可以绕过PageCache。]]></content>
      <categories>
        <category>IO</category>
      </categories>
      <tags>
        <tag>IO</tag>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[零拷贝的问题]]></title>
    <url>%2F2019%2F09%2F11%2F%E9%9B%B6%E6%8B%B7%E8%B4%9D%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[传统的IO的操作读操作缓冲技术是IO的基础，一次读取大量数据放在缓冲区，需要的时候从缓冲区取得数据。 详细可见：内核缓冲区问题 一个完整的read操作：当应用程序发起read请求后，会检查内核空间内是否有需要读取的数据（pageCache）,如果有，直接copy到用户空间；如果没有，那么需要从磁盘读取，磁盘控制器通过DMA操作将数据从磁盘读取到内核空间，然后才从内核空间拷贝到用户空间。 DMA：不需要通过CPU调度，由DMA控制器来处理，不需要麻烦CPU。 读写操作使用传统的I/O程序读取文件内容, 并写入到另一个文件(或Socket)。性能开销比较大： 上下文切换(context switch), 此处有4次用户态和内核态的切换 Buffer内存开销, 一个是应用程序buffer, 另一个是系统读取buffer以及socket buffer。 需要进行四次拷贝，2次DMA copy和两次CPU copy。传统IO四次内容拷贝： 先将文件内容从磁盘中拷贝到操作系统buffer 再从操作系统buffer拷贝到程序应用buffer 从程序buffer拷贝到socket buffer 从socket buffer拷贝到协议引擎.零拷贝 MMap将物理内存映射到虚拟内存中。 在mmap之后，并没有在将文件内容加载到物理页上，只上在虚拟内存中分配了地址空间。当进程在访问这段地址时，若虚拟内存对应的page没有在物理内存中缓存，则产生”缺页”，将相应的页面载入物理内存。 mmap()会返回一个指针ptr，它指向进程逻辑地址空间中的一个地址，这样以后，进程无需再调用read或write对文件进行读写，而只需要通过ptr就能够操作文件。但是ptr所指向的是一个逻辑地址，要操作其中的数据，必须通过MMU将逻辑地址转换成物理地址，若MMU没有相应的映射，产生缺页中断，将页面重新置入内存。 省去了从内核缓冲区复制到用户空间的过程，只有从磁盘调入到物理内存的过程。它的最终目的是将磁盘中的文件映射到用户进程的虚拟地址空间，实现用户进程对文件的直接读写，减少了文件复制的开销，提高了用户的访问效率。 mmap+write如何映射，见更多细节。 sendFile拷贝过程： 首先通过DMA copy将数据从磁盘读取到kernel buffer中 然后通过CPU copy将数据从kernel buffer copy到sokcet buffer中 最终通过DMA copy将socket buffer中数据copy到网卡buffer中发送sendfile与read/write方式相比，少了一次复制，少了两次上下文切换。改进后的sendFilesendFile中间copy到socket buffer这一步仍是多余的。改进后的：拷贝过程： DMA copy将磁盘数据copy到kernel buffer中 向socket buffer中追加当前要发送的数据在kernel buffer中的位置和偏移量 DMA gather copy根据socket buffer中的位置和偏移量直接将kernel buffer中的数据copy到网卡上。 改进后的只有两次复制了。]]></content>
      <categories>
        <category>IO</category>
      </categories>
      <tags>
        <tag>IO</tag>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java nio操作实践]]></title>
    <url>%2F2019%2F07%2F26%2Fjava-nio%E6%93%8D%E4%BD%9C%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[java文件中文件IO主要包括普通IO，FileChannel以及MMap。本文主要介绍FileChannel以及MMap的一些原理以及使用，理解他们最好需要了解有关pageCache，内存零拷贝，堆外缓存的一些知识。 有关pageCache可见 PageCache和DirectIO ， 有关零拷贝可见 零拷贝问题 。 获取方式1234//获取FileChannelFileChannel fileChannel = new RandomAccessFile(new File("db.data"), "rw").getChannel();//获取MMapMappedByteBuffer mappedByteBuffer = fileChannel.map(FileChannel.MapMode.READ_WRITE, 0, filechannel.size()); FileChannel 写`` 123456789101112131415// 写byte[] data = new byte[4096];long position = 1024L;//指定 position 写入 data中 的数据fileChannel.write(ByteBuffer.wrap(data), position);//从当前文件指针的位置写入 4kb 的数据fileChannel.write(ByteBuffer.wrap(data));// 读ByteBuffer buffer = ByteBuffer.allocate(4096);long position = 1024L;//指定 position 读取 4kb 的数据到bufferfileChannel.read(buffer,position)；//从当前文件指针的位置读取 4kb 的数据fileChannel.read(buffer); FileChannel+ByteBuffer可以达到写入速度比较快，要是没有缓冲区的存在，FileChannel写入速度并不比普通IO，一般来说缓冲区的大小是由磁盘决定的。 那么，FileChannel是直接把ByteBuffer写到磁盘的吗？ 不是，中间还隔着一个PageCache。当ByteBUffer是堆内内存时，数据需要经历ByteBuffer-&gt;内核空间-&gt;PageCache。当ByteBufefr是直接内存，则省略到了从用户空间到内核空间的复制，直接ByteBuffer-&gt;PageCache，然后再从PageCache写回磁盘。 我们都知道磁盘 IO 和内存 IO 的速度可是相差了好几个数量级。我们可以认为 filechannel.write 写入 PageCache 便是完成了落盘操作，但实际上，操作系统最终帮我们完成了 PageCache 到磁盘的最终写入（这是异步的），理解了这个概念，你就应该能够理解 FileChannel 为什么提供了一个 force() 方法，用于通知操作系统进行及时的刷盘。 例如，RocketMQ刷盘方式： 异步刷盘方式：在返回写成功状态时，消息可能只是被写入了内存的PAGECACHE，写操作的返回快，吞吐量大；当内存里的消息量积累到一定程度时，统一触发写磁盘操作，快速写入 同步刷盘方式：在返回写成功状态时，消息已经被写入磁盘。具体流程是，消息写入内存的PAGECACHE后，立刻通知刷盘线程刷盘，然后等待刷盘完成，刷盘线程执行完成后唤醒等待的线程，返回消息写成功的状态。 MMap读写`` 12345678910111213141516171819// 写byte[] data = new byte[4];int position = 8;//从当前 mmap 指针的位置写入 4b 的数据mappedByteBuffer.put(data);//指定 position 写入 4b 的数据MappedByteBuffer subBuffer = mappedByteBuffer.slice();subBuffer.position(position);subBuffer.put(data);// 读byte[] data = new byte[4];int position = 8;//从当前 mmap 指针的位置读取 4b 的数据mappedByteBuffer.get(data)；//指定 position 读取 4b 的数据MappedByteBuffer subBuffer = mappedByteBuffer.slice();subBuffer.position(position);subBuffer.get(data); mmap是把文件映射到用户空间里的虚拟内存，这样就省去了从用户空间到内核空间的拷贝，这样，当我们需要向文件中写入数据时，先看虚拟内存中有没有对应的地址，即有没有将物理地址映射到虚拟内存，要是有的话，可以像操作内存一样操作这个文件，没有的话，产生缺页，加载相对应的页。 mmap 把文件映射到用户空间里的虚拟内存，省去了从内核缓冲区复制到用户空间的过程，文件中的位置在虚拟内存中有了对应的地址，可以像操作内存一样操作这个文件，相当于已经把整个文件放入内存，但在真正使用到这些数据前却不会消耗物理内存，也不会有读写磁盘的操作，只有真正使用这些数据时，也就是图像准备渲染在屏幕上时，虚拟内存管理系统 VMS 才根据缺页加载的机制从磁盘加载对应的数据块到物理内存进行渲染。这样的文件读写文件方式少了数据从内核缓存到用户空间的拷贝，效率很高。 但是，MMap是不适用于大量数据的。 因为一次map的大小在1.5G左右，要是大量数据的话必然要进行多次MMap，重复的map会带来虚拟内存回收，重新分配的问题。 MMAP 使用的是虚拟内存，和 PageCache 一样是由操作系统来控制刷盘的，虽然可以通过 force() 来手动控制，但这个时间把握不好，在小内存场景下会很令人头疼。 MMAP 的回收问题，当 MappedByteBuffer 不再需要时，可以手动释放占用的虚拟内存，但非常麻烦。 所以，对于小数据量刷盘的情况下，可以使用MMap，例如索引，但是其他场景，FileChannel+DirectByteBuffer完全可以替代，并且性能跟MMap差不多。 堆内内存与堆外内存 堆内内存 堆外内存 底层实现 数组，JVM 内存 unsafe.allocateMemory(size)返回直接内存 分配大小限制 -Xms-Xmx 配置的 JVM 内存相关，并且数组的大小有限制，在做测试时发现，当 JVM free memory 大于 1.5G 时，ByteBuffer.allocate(900M) 时会报错 可以通过 -XX:MaxDirectMemorySize 参数从 JVM 层面去限制，同时受到机器虚拟内存（说物理内存不太准确）的限制 垃圾回收 不必多说，gc自动回收 当 DirectByteBuffer 不再被使用时，会出发内部 cleaner 的钩子，保险起见，可以考虑手动回收：((DirectBuffer) buffer).cleaner().clean(); 内存复制 堆内内存 -&gt; 堆外内存 -&gt; pageCache 堆外内存 -&gt; pageCache 对于堆外内存，可使用池+堆外内存组合。例如：ThreadLocal&lt;ByteBuffer&gt; 和 ThreadLocal&lt;byte[]&gt;。 UnsafeReferrenceIO操作读写测试]]></content>
      <categories>
        <category>IO</category>
      </categories>
      <tags>
        <tag>java IO</tag>
      </tags>
  </entry>
</search>
